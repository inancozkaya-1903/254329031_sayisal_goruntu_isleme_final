# -*- coding: utf-8 -*-
"""Sayısal Görüntü İşleme Final Sınavı.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1evLZLZixUPxphVgbSALfrIkOQYt_V6HE

*   TC. ÜSKÜDAR ÜNİVERSİTESİ
*   SAYISAL GÖRÜNTÜ İŞLEME DERSİ
FİNALİ
*   Öğrenci Numarası: 254329031
*   İsim Soyisim: Şahin İnanç ÖZKAYA

#1. Veri Yükleme
##1.1. Kütüphanelerin İçe Aktarılması
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
import os
from PIL import Image
from google.colab import drive

"""##1.2. Veri Setinin Yüklenmesi"""

#https://drive.google.com/drive/folders/1tn8SVWSsRGb1jSOzRIKKhcI9veM_oHQO?usp=drive_link

DRIVE_PATH = '/content/drive/MyDrive/skin_cancer'
LOCAL_PATH = '/content/skin_cancer_local'

!cp -r "{DRIVE_PATH}" "{LOCAL_PATH}"

dataset_path = '/content/skin_cancer_local'

data_list = []

for root, dirs, files in os.walk(dataset_path):
    for filename in files:
        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):
            full_path = os.path.join(root, filename)

            label = root.split(os.path.sep)[-1]

            data_list.append({
                'file_path': full_path,
                'label': label
            })

train_df = pd.DataFrame(data_list)

display(train_df.head())

print(f"\nToplam Görüntü Sayısı: {len(train_df)}")

"""#1.3. Veri Özelliklerinin İncelenmesi"""

widths = []
heights = []
channels = []
file_sizes_kb = []

for path in train_df['file_path']:
    try:
        size_bytes = os.path.getsize(path)
        file_sizes_kb.append(size_bytes / 1024)

        img = cv2.imread(path)
        if img is not None:
            h, w, c = img.shape
            heights.append(h)
            widths.append(w)
            channels.append(c)
    except:
        pass

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.scatter(widths, heights, alpha=0.5, c='blue', s=15)
plt.title("Görüntü Çözünürlük Analizi (Yükseklik-Genişlik)")
plt.xlabel("Genişlik (px)")
plt.ylabel("Yükseklik (px)")
plt.grid(True, linestyle='--', alpha=0.5)

plt.subplot(1, 2, 2)
sns.histplot(file_sizes_kb, kde=True, color='green')
plt.title("Dosya Boyutu Dağılımı")
plt.xlabel("Dosya Boyutu (KB)")

plt.tight_layout()
plt.show()

print("\n--- ANALİZ SONUÇLARI ---")
print(f"1. Çözünürlük Analizi:")
print(f"   - Min Çözünürlük: {np.min(heights)}x{np.min(widths)}")
print(f"   - Max Çözünürlük: {np.max(heights)}x{np.max(widths)}")
print(f"   - Ort. Çözünürlük: {int(np.mean(heights))}x{int(np.mean(widths))}")

print(f"\n2. Kanal Sayısı Doğrulaması:")
unique_channels = np.unique(channels)
if len(unique_channels) == 1 and unique_channels[0] == 3:
    print(f"   - SONUÇ: Tüm görüntüler 3 kanallıdır (RGB Formatında).")
else:
    print(f"   - SONUÇ: Farklı kanal sayıları tespit edildi: {unique_channels}")

print(f"\n3. Dosya Boyutu Analizi:")
print(f"   - Ortalama Boyut: {np.mean(file_sizes_kb):.2f} KB")
print(f"   - En Büyük Dosya: {np.max(file_sizes_kb):.2f} KB")

"""#2. Görüntü Yükleme ve Görselleştirme
##2.1. Rastgele Görüntüler Seçme

"""

import cv2
import numpy as np
import matplotlib.pyplot as plt

# 9 örnek seç
random9_train_df = train_df.sample(n=9, random_state=50).reset_index(drop=True)

# ✅ Pipeline kolonları
for col in ["img_bgr", "img_rgb", "img_gray"]:
    if col not in random9_train_df.columns:
        random9_train_df[col] = None

# A4 / 4 sütun (8 örnek + altta 9. ortada)
fig, axes = plt.subplots(5, 4, figsize=(8.27, 11.69), dpi=300)
for r in range(5):
    for c in range(4):
        axes[r, c].axis("off")

def put_pair_rgb_gray(r, c0, idx):
    row = random9_train_df.iloc[idx]
    img_bgr = cv2.imread(row["file_path"])

    if img_bgr is None:
        return

    img_rgb  = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)

    # ✅ df'ye yaz
    random9_train_df.at[idx, "img_bgr"]  = img_bgr
    random9_train_df.at[idx, "img_rgb"]  = img_rgb
    random9_train_df.at[idx, "img_gray"] = img_gray

    # Sol: RGB
    axes[r, c0].imshow(img_rgb)
    axes[r, c0].set_title(f"Ö{idx+1} RGB\n{row['label']}", fontsize=9, pad=2)
    axes[r, c0].axis("off")

    # Sağ: GRAY
    axes[r, c0+1].imshow(img_gray, cmap="gray", vmin=0, vmax=255)
    axes[r, c0+1].set_title(f"Ö{idx+1} GRAY\n{row['label']}", fontsize=9, pad=2)
    axes[r, c0+1].axis("off")

# İlk 8 örnek: 4 satır x 2 örnek
k = 0
for r in range(4):
    put_pair_rgb_gray(r, 0, k); k += 1
    put_pair_rgb_gray(r, 2, k); k += 1

# 9. örnek: altta ortada (col 1-2)
put_pair_rgb_gray(4, 1, 8)

plt.tight_layout(pad=1.0)
plt.show()

"""##2.2. Rastgele Görüntülerin İstatistiksel Özellikleri"""

import numpy as np
import pandas as pd

stats_data = []

for idx, row in random9_train_df.iterrows():
    # ✅ Önceki hücrede hazırlandı: tekrar imread yok
    img_rgb  = row.get("img_rgb", None)
    img_gray = row.get("img_gray", None)

    if img_rgb is None or img_gray is None:
        continue

    rgb_min  = float(np.min(img_rgb))
    rgb_max  = float(np.max(img_rgb))
    rgb_mean = float(np.mean(img_rgb))
    rgb_std  = float(np.std(img_rgb))

    gray_min  = float(np.min(img_gray))
    gray_max  = float(np.max(img_gray))
    gray_mean = float(np.mean(img_gray))
    gray_std  = float(np.std(img_gray))

    stats_data.append({
        "Örnek No": int(idx + 1),
        "Sınıf": row["label"],

        "RGB Min": rgb_min,
        "RGB Max": rgb_max,
        "RGB Ort": f"{rgb_mean:.2f}",
        "RGB Std": f"{rgb_std:.2f}",

        "Gray Min": gray_min,
        "Gray Max": gray_max,
        "Gray Ort": f"{gray_mean:.2f}",
        "Gray Std": f"{gray_std:.2f}"
    })

stats_df = pd.DataFrame(stats_data)
display(stats_df)

"""##2.3. Histogram Çizimi (RGB + Grayscale)"""

import numpy as np
import matplotlib.pyplot as plt

# Eğer önceki hücrede kolonlar dolu değilse, güvenlik için uyarı:
# (Bu satırları istersen kaldır)
assert "img_rgb" in random9_train_df.columns and "img_gray" in random9_train_df.columns, \
    "Önceki hücrede img_rgb ve img_gray kolonları oluşturulmalı."

fig, axes = plt.subplots(5, 4, figsize=(8.27, 11.69), dpi=300)
for r in range(5):
    for c in range(4):
        axes[r, c].axis("off")

def put_hist_pair(r, c0, idx):
    row = random9_train_df.iloc[idx]
    img_rgb  = row.get("img_rgb", None)
    img_gray = row.get("img_gray", None)

    if img_rgb is None or img_gray is None:
        return

    ax_rgb  = axes[r, c0]
    ax_gray = axes[r, c0+1]

    # --- RGB histogram (img_rgb: HxWx3, order RGB) ---
    ax_rgb.axis("on")
    for ch, col, name in [(0, "r", "R"), (1, "g", "G"), (2, "b", "B")]:
        hist = np.bincount(img_rgb[:, :, ch].ravel(), minlength=256)
        ax_rgb.plot(hist, color=col, alpha=0.8, linewidth=0.8, label=name)
    ax_rgb.set_xlim(0, 255)
    ax_rgb.set_title(f"Ö{idx+1} RGB Hist\n{row['label']}", fontsize=9, pad=2)
    ax_rgb.grid(True, alpha=0.25, linestyle="--", linewidth=0.5)
    ax_rgb.tick_params(labelsize=7)

    # --- GRAY histogram ---
    ax_gray.axis("on")
    hist_g = np.bincount(img_gray.ravel(), minlength=256)
    ax_gray.plot(hist_g, color="black", alpha=0.9, linewidth=0.9)
    ax_gray.set_xlim(0, 255)
    ax_gray.set_title(f"Ö{idx+1} GRAY Hist\n{row['label']}", fontsize=9, pad=2)
    ax_gray.grid(True, alpha=0.25, linestyle="--", linewidth=0.5)
    ax_gray.tick_params(labelsize=7)

# İlk 8 örnek: 4 satır x 2 örnek
k = 0
for r in range(4):
    put_hist_pair(r, 0, k); k += 1
    put_hist_pair(r, 2, k); k += 1

# 9. örnek: altta ortada (col 1-2)
put_hist_pair(4, 1, 8)

plt.tight_layout(pad=1.0)
plt.show()

"""#2) Pre-Processing

##2.1 Crop (Dynamic)
"""

import numpy as np
import matplotlib.pyplot as plt

# =========================
# Option A (improved): Border-safe crop (ONLY CROP)
# (Aynı fonksiyonlar - değiştirmedim)
# =========================
def _roi_bbox(gray_crop, dark_q=0.30):
    thr = np.quantile(gray_crop, dark_q)
    mask = (gray_crop <= thr).astype(np.uint8)

    ys, xs = np.where(mask > 0)
    if len(xs) == 0:
        return None

    x1, x2 = xs.min(), xs.max()
    y1, y2 = ys.min(), ys.max()
    return (x1, y1, x2, y2)

def _danger_near_border_bbox(gray_crop, gap_px=18, dark_q=0.30):
    h, w = gray_crop.shape
    if h < 32 or w < 32:
        return True

    bb = _roi_bbox(gray_crop, dark_q=dark_q)
    if bb is None:
        return False

    x1, y1, x2, y2 = bb
    if x1 < gap_px or y1 < gap_px or (w - 1 - x2) < gap_px or (h - 1 - y2) < gap_px:
        return True
    return False

def crop_border_safe(gray,
                     base_trim=0.045,
                     min_trim=0.0,
                     step=0.005,
                     gap_px=10,
                     dark_q=0.30):

    if gray is None:
        return None

    h, w = gray.shape[:2]
    trim = base_trim

    while True:
        dy = int(round(h * trim))
        dx = int(round(w * trim))

        y1, y2 = dy, h - dy
        x1, x2 = dx, w - dx

        if (y2 - y1) < 32 or (x2 - x1) < 32:
            return gray.copy()

        crop = gray[y1:y2, x1:x2].copy()

        if _danger_near_border_bbox(crop, gap_px=gap_px, dark_q=dark_q) and trim > min_trim:
            trim = max(min_trim, trim - step)
            if trim <= 1e-9:
                return gray.copy()
            continue

        return crop

# =========================
# 9 örnek: random9_train_df üzerinden ilerle
# - Girdi: img_gray
# - Çıktı: img_crop
# =========================
# Eğer img_gray kolonun yoksa bu hücreyi çalıştırmadan önce "RGB|GRAY" hücreni çalıştırmalısın.
assert "img_gray" in random9_train_df.columns, "img_gray kolonu yok. Önce RGB->GRAY hazırlayan hücreyi çalıştır."

# ✅ output kolonu
if "img_crop" not in random9_train_df.columns:
    random9_train_df["img_crop"] = None

fig, axes = plt.subplots(5, 4, figsize=(8.27, 11.69), dpi=300)
for r in range(5):
    for c in range(4):
        axes[r, c].axis("off")

def put_pair(r, c0, idx):
    row = random9_train_df.iloc[idx]
    gray = row["img_gray"]

    if gray is None:
        return

    cropped = crop_border_safe(
        gray,
        base_trim=0.045,
        min_trim=0.015,
        step=0.005,
        gap_px=22,
        dark_q=0.30
    )

    # ✅ df'ye yaz (sonraki hücre için hazır)
    random9_train_df.at[idx, "img_crop"] = cropped

    axes[r, c0].imshow(gray, cmap="gray", vmin=0, vmax=255)
    axes[r, c0].set_title(f"Örnek {idx+1} - Orijinal\n{row['label']}", fontsize=9, pad=2)

    axes[r, c0+1].imshow(cropped, cmap="gray", vmin=0, vmax=255)
    axes[r, c0+1].set_title(f"Örnek {idx+1} - Crop\n{row['label']}", fontsize=9, pad=2)

k = 0
for r in range(4):
    put_pair(r, 0, k); k += 1
    put_pair(r, 2, k); k += 1

# 9. örnek ortada
put_pair(4, 1, 8)

plt.tight_layout(pad=1.0)
plt.show()

"""## 2.2 Kontrast İyileştirme

##A) Kontrast Germe (SEÇİLEN)
"""

import numpy as np
import matplotlib.pyplot as plt

# =========================
# 2.2 Contrast Stretch (Adaptive): ONLY percentile stretch
# (Aynı fonksiyonlar - crop yok, imread yok)
# =========================
def contrast_stretch_percentile(gray, p_low=2, p_high=98):
    if gray is None:
        return None
    if gray.dtype != np.uint8:
        gray = gray.astype(np.uint8)

    lo, hi = np.percentile(gray, (p_low, p_high))
    if hi <= lo + 1e-6:
        return gray.copy()

    stretched = (gray.astype(np.float32) - lo) * (255.0 / (hi - lo))
    stretched = np.clip(stretched, 0, 255).astype(np.uint8)
    return stretched

def adaptive_percentiles(gray_crop,
                         soft=(6, 99),
                         mid=(5, 97),
                         aggressive=(2, 98),
                         thr_flat=0.20,
                         thr_mid=0.33):
    p2, p98 = np.percentile(gray_crop, (2, 98))
    dyn_ratio = (p98 - p2) / 255.0

    if dyn_ratio < thr_flat:
        return aggressive
    elif dyn_ratio < thr_mid:
        return mid
    else:
        return soft

def adaptive_contrast_stretch(gray_crop):
    p_low, p_high = adaptive_percentiles(gray_crop)
    lo, hi = np.percentile(gray_crop, (p_low, p_high))
    if (hi - lo) < 12:
        return gray_crop.copy(), (p_low, p_high)
    return contrast_stretch_percentile(gray_crop, p_low=p_low, p_high=p_high), (p_low, p_high)

# =========================
# PIPELINE: input=img_crop  -> output=img_stretch + p_low/p_high
# =========================
assert "img_crop" in random9_train_df.columns, "img_crop kolonu yok. Önce crop hücresini çalıştır."
samples = random9_train_df.reset_index(drop=True)

for col in ["img_stretch", "p_low", "p_high"]:
    if col not in samples.columns:
        samples[col] = None

fig, axes = plt.subplots(5, 4, figsize=(8.27, 11.69), dpi=300)
for r in range(5):
    for c in range(4):
        axes[r, c].axis("off")

def put_pair_crop_stretch(r, c0, idx):
    row = samples.iloc[idx]
    cropped = row["img_crop"]

    if cropped is None:
        return

    stretched, (p_low, p_high) = adaptive_contrast_stretch(cropped)

    # ✅ df'ye yaz (sonraki hücreler için hazır)
    samples.at[idx, "img_stretch"] = stretched
    samples.at[idx, "p_low"] = int(p_low)
    samples.at[idx, "p_high"] = int(p_high)

    # Sol: Crop
    axes[r, c0].imshow(cropped, cmap="gray", vmin=0, vmax=255)
    axes[r, c0].set_title(f"Ö{idx+1} Crop\n{row['label']}", fontsize=9, pad=2)

    # Sağ: Crop + Stretch
    axes[r, c0+1].imshow(stretched, cmap="gray", vmin=0, vmax=255)
    axes[r, c0+1].set_title(f"Ö{idx+1} Stretch\n({p_low}-{p_high}) | {row['label']}", fontsize=9, pad=2)

k = 0
for r in range(4):
    put_pair_crop_stretch(r, 0, k); k += 1
    put_pair_crop_stretch(r, 2, k); k += 1

put_pair_crop_stretch(4, 1, 8)

plt.tight_layout(pad=1.0)
plt.show()

# ✅ pipeline df güncellensin (random9_train_df referansını koru)
random9_train_df = samples

"""##B) Histogram Eşitleme"""

import cv2
import numpy as np
import matplotlib.pyplot as plt

# =========================
# 2.2 Histogram Equalization (pipeline)
# Input : img_crop
# Output: img_eq (chosen mode)
# =========================
def hist_equalize(gray_crop):
    if gray_crop is None:
        return None
    if gray_crop.dtype != np.uint8:
        gray_crop = gray_crop.astype(np.uint8)
    return cv2.equalizeHist(gray_crop)

def clahe_equalize(gray_crop, clip_limit=2.0, tile_grid_size=(8, 8)):
    if gray_crop is None:
        return None
    if gray_crop.dtype != np.uint8:
        gray_crop = gray_crop.astype(np.uint8)
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    return clahe.apply(gray_crop)

# MODE: "equalize" (global) veya "clahe"
MODE = "clahe"   # <-- burada değiştir

CLAHE_CLIP = 2.0
CLAHE_TILE = (8, 8)

assert "img_crop" in random9_train_df.columns, "img_crop kolonu yok. Önce crop hücresini çalıştır."
samples = random9_train_df.reset_index(drop=True)

# ✅ output kolonları
if "img_eq" not in samples.columns:
    samples["img_eq"] = None
if "eq_tag" not in samples.columns:
    samples["eq_tag"] = None

# ---- A4 / 4 sütun düzen ----
fig, axes = plt.subplots(5, 4, figsize=(8.27, 11.69), dpi=300)
for r in range(5):
    for c in range(4):
        axes[r, c].axis("off")

def put_pair(r, c0, idx):
    row = samples.iloc[idx]
    cropped = row["img_crop"]
    if cropped is None:
        return

    # 2.2 Equalize (crop sonrası)
    if MODE == "equalize":
        eq = hist_equalize(cropped)
        eq_tag = "HistEq"
    else:
        eq = clahe_equalize(cropped, clip_limit=CLAHE_CLIP, tile_grid_size=CLAHE_TILE)
        eq_tag = f"CLAHE({CLAHE_CLIP},{CLAHE_TILE[0]}x{CLAHE_TILE[1]})"

    # ✅ df'ye yaz (sonraki hücreler için hazır)
    samples.at[idx, "img_eq"] = eq
    samples.at[idx, "eq_tag"] = eq_tag

    # Sol: Crop
    axes[r, c0].imshow(cropped, cmap="gray", vmin=0, vmax=255)
    axes[r, c0].set_title(f"Ö{idx+1} Crop\n{row['label']}", fontsize=9, pad=2)

    # Sağ: Crop + Equalize
    axes[r, c0+1].imshow(eq, cmap="gray", vmin=0, vmax=255)
    axes[r, c0+1].set_title(f"Ö{idx+1} {eq_tag}\n{row['label']}", fontsize=9, pad=2)

k = 0
for r in range(4):
    put_pair(r, 0, k); k += 1
    put_pair(r, 2, k); k += 1

# 9. örnek ortada
put_pair(4, 1, 8)

plt.tight_layout(pad=1.0)
plt.show()

# ✅ pipeline df güncellensin
random9_train_df = samples

"""### Kontrast Artırma Yöntemi Seçimi (Kontrast Germe vs. Histogram Eşitleme)

Bu çalışmada, kırpma (crop) sonrası görüntü kontrastını artırmak için iki yöntem karşılaştırılmıştır:  
(i) **Percentile tabanlı kontrast germe (contrast stretching)** ve  
(ii) **CLAHE tabanlı histogram eşitleme (Adaptive Histogram Equalization)**.

Karşılaştırma sonucunda, nihai ön-işleme hattı için **percentile tabanlı kontrast germe** yöntemi tercih edilmiştir. Seçim gerekçeleri aşağıdadır:

- **Daha kontrollü kontrast artışı:** Kontrast germe, görüntünün global yoğunluk dağılımını belirli yüzdelikler arasında yeniden ölçekleyerek kontrastı artırır. Bu, lezyon/arka plan ayrımını güçlendirirken görüntüyü aşırı “sertleştirme” eğilimini sınırlamaktadır.
- **Arka plan gürültüsünü büyütmeme avantajı:** CLAHE, yerel histogram eşitleme yaptığı için düşük kontrastlı bölgelerde yalnızca lezyon yapısını değil, aynı zamanda deri dokusu, saç ve sensör/aydınlatma kaynaklı heterojenlikleri de belirginleştirebilmektedir. Bu durum, modelin lezyon yerine arka plan dokusuna dayalı yanıltıcı ipuçları (spurious features) öğrenme riskini artırabilir.
- **Genellenebilirlik ve stabilite:** Percentile germe, örnekler arası daha tutarlı bir görsel iyileştirme sağlar. CLAHE ise parametrelerine (clipLimit, tileGridSize) daha hassas olup bazı örneklerde gereğinden fazla gürültü ve doku kontrastı üretebilmektedir.

Bu nedenlerle, sonraki aşamalarda (özellik çıkarımı ve sınıflandırma modelleri) daha kararlı ve genellenebilir bir giriş temsili sağlamak amacıyla **kontrast germe** yöntemi ile ilerlenmiştir.

## 2.3 Gürültü Azaltma / Blurring

##Median Blur (SEÇİLEN)
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt

# =========================
# 2.3 Median Blur (input = img_stretch)
# =========================
def median_blur(gray, k=3):
    if gray is None:
        return None
    k = int(k)
    if k < 3:
        k = 3
    if k % 2 == 0:
        k += 1
    if gray.dtype != np.uint8:
        gray = gray.astype(np.uint8)
    return cv2.medianBlur(gray, k)

# Pipeline kontrolü
assert "img_stretch" in random9_train_df.columns, "img_stretch kolonu yok. Önce crop+contrast stretch hücresini çalıştır."

samples = random9_train_df.reset_index(drop=True)

# ✅ output kolonu
if "img_median" not in samples.columns:
    samples["img_median"] = None
if "median_k" not in samples.columns:
    samples["median_k"] = None

MEDIAN_K = 5

fig, axes = plt.subplots(5, 4, figsize=(8.27, 11.69), dpi=300)
for r in range(5):
    for c in range(4):
        axes[r, c].axis("off")

def put_pair(r, c0, idx):
    row = samples.iloc[idx]
    stretched = row["img_stretch"]
    if stretched is None:
        return

    med = median_blur(stretched, k=MEDIAN_K)

    # ✅ df'ye yaz
    samples.at[idx, "img_median"] = med
    samples.at[idx, "median_k"] = int(MEDIAN_K)

    axes[r, c0].imshow(stretched, cmap="gray", vmin=0, vmax=255)
    axes[r, c0].set_title(f"Ö{idx+1} Stretch\n{row['label']}", fontsize=9, pad=2)

    axes[r, c0+1].imshow(med, cmap="gray", vmin=0, vmax=255)
    axes[r, c0+1].set_title(f"Ö{idx+1} Stretch+Median (k={MEDIAN_K})\n{row['label']}", fontsize=9, pad=2)

k = 0
for r in range(4):
    put_pair(r, 0, k); k += 1
    put_pair(r, 2, k); k += 1

# 9. örnek ortada
put_pair(4, 1, 8)

plt.tight_layout(pad=1.0)
plt.show()

# ✅ df güncelle
random9_train_df = samples

"""##Gaussian Blur"""

import cv2
import numpy as np
import matplotlib.pyplot as plt

# =========================
# 2.3 Gaussian Blur (input = img_stretch)
# =========================
def gaussian_blur(gray, k=(5, 5), sigma_x=2):
    if gray is None:
        return None
    if gray.dtype != np.uint8:
        gray = gray.astype(np.uint8)

    # k tek sayılar olmalı (OpenCV bazen kabul etse de garanti olsun)
    kx, ky = int(k[0]), int(k[1])
    if kx % 2 == 0: kx += 1
    if ky % 2 == 0: ky += 1

    return cv2.GaussianBlur(gray, (kx, ky), sigmaX=sigma_x)

# Pipeline kontrolü
assert "img_stretch" in random9_train_df.columns, "img_stretch kolonu yok. Önce crop+contrast stretch hücresini çalıştır."

samples = random9_train_df.reset_index(drop=True)

# ✅ output kolonları
if "img_gaussian" not in samples.columns:
    samples["img_gaussian"] = None
if "gauss_k" not in samples.columns:
    samples["gauss_k"] = None
if "gauss_sigma_x" not in samples.columns:
    samples["gauss_sigma_x"] = None

GAUSS_K = (5, 5)
SIGMA_X = 2

fig, axes = plt.subplots(5, 4, figsize=(8.27, 11.69), dpi=300)
for r in range(5):
    for c in range(4):
        axes[r, c].axis("off")

def put_pair(r, c0, idx):
    row = samples.iloc[idx]
    stretched = row["img_stretch"]
    if stretched is None:
        return

    gblur = gaussian_blur(stretched, k=GAUSS_K, sigma_x=SIGMA_X)

    # ✅ df'ye yaz
    samples.at[idx, "img_gaussian"] = gblur
    samples.at[idx, "gauss_k"] = str(GAUSS_K)
    samples.at[idx, "gauss_sigma_x"] = float(SIGMA_X)

    axes[r, c0].imshow(stretched, cmap="gray", vmin=0, vmax=255)
    axes[r, c0].set_title(f"Ö{idx+1} Stretch\n{row['label']}", fontsize=9, pad=2)

    axes[r, c0+1].imshow(gblur, cmap="gray", vmin=0, vmax=255)
    axes[r, c0+1].set_title(f"Ö{idx+1} Stretch+Gaussian\n(k={GAUSS_K}, σx={SIGMA_X}) | {row['label']}", fontsize=9, pad=2)

k = 0
for r in range(4):
    put_pair(r, 0, k); k += 1
    put_pair(r, 2, k); k += 1

# 9. örnek ortada
put_pair(4, 1, 8)

plt.tight_layout(pad=1.0)
plt.show()

# ✅ df güncelle
random9_train_df = samples

"""### Gürültü Azaltma Yöntemi Seçimi (Median Blur vs. Gaussian Blur)

Bu çalışmada, kontrast germe (contrast stretching) uygulanmış görüntülerde ortaya çıkan gürültüyü azaltmak amacıyla iki filtre karşılaştırılmıştır:  
(i) **Median Blur** ve  
(ii) **Gaussian Blur**.

Karşılaştırma sonucunda, nihai ön-işleme hattı için **Median Blur (k=5)** yöntemi tercih edilmiştir. Seçim gerekçesi aşağıdadır:

- **Detay koruyarak gürültü bastırma:** Kontrast germe sonrası belirginleşen benekli/salt-pepper benzeri gürültüyü Median Blur daha etkili şekilde azaltırken, lezyon sınırlarını ve yapı/doku detaylarını Gaussian Blur’a kıyasla daha az bulanıklaştırarak korumuştur. Bu nedenle, gürültü azaltımı ile lezyon morfolojisinin korunması arasında daha dengeli bir çıktı verdiği gözlenmiştir.

# 3) Thresholding ile Segmentasyon

## 3.1 Eşik Değerlerinin Belirlenmesi
"""

import numpy as np
import pandas as pd
import cv2
from skimage import filters

# =========================
# 3.1 Eşik Değerlerinin Belirlenmesi
# Input: median uygulanmış görüntüler (uint8 gray) -> median_imgs
# Output: Her yöntem için eşik değerleri tablosu
# =========================

# ---- Guard ----
if "median_imgs" not in globals():
    raise NameError("median_imgs bulunamadı. Önce median blur uygulanmış görüntüleri (median_imgs) üreten hücreyi çalıştır.")
if "random9_train_df" not in globals():
    raise NameError("random9_train_df bulunamadı. Önce 9 örneği sabitleyen dataframe'i (random9_train_df) oluştur.")

if len(median_imgs) != 9:
    raise ValueError(f"median_imgs uzunluğu {len(median_imgs)}. Bu hücre 9 örnek (len=9) bekliyor.")

# ---- 1) Global threshold tanımı (tek T) ----
def global_threshold_T(gray_u8):
    """
    Basit global eşik (tek değer T).
    Burada mean - 0.5*std kullanıyoruz (deri görüntülerinde pratik bir baseline).
    """
    m = float(np.mean(gray_u8))
    s = float(np.std(gray_u8))
    T = int(np.clip(m - 0.5 * s, 0, 255))
    return T

# ---- 2) Otsu threshold (tek T) ----
def otsu_threshold_T(gray_u8):
    T, _ = cv2.threshold(gray_u8, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    return int(T)

# ---- 3) skimage.filters.try_all_threshold "benzeri": birden çok yöntem için T üret ----
def skimage_thresholds(gray_u8):
    """
    try_all_threshold'in yaptığı gibi birden fazla yöntemin eşik değerlerini çıkarır.
    (try_all_threshold esasen görselleştirme helper'ıdır; burada sayısal T'leri raporluyoruz.)
    """
    x = gray_u8.astype(np.float32)

    out = {}
    # skimage threshold fonksiyonları:
    out["mean"]     = float(filters.threshold_mean(x))
    out["isodata"]  = float(filters.threshold_isodata(x))
    out["li"]       = float(filters.threshold_li(x))
    out["yen"]      = float(filters.threshold_yen(x))
    out["triangle"] = float(filters.threshold_triangle(x))

    # bazı görüntülerde threshold_minimum hata verebilir (multi-modal şartı)
    try:
        out["minimum"] = float(filters.threshold_minimum(x))
    except Exception:
        out["minimum"] = np.nan

    return out

# ---- Hesapla ----
rows = []
for idx in range(9):
    img = median_imgs[idx]
    label = random9_train_df.iloc[idx]["label"] if idx < len(random9_train_df) else None

    if img is None:
        rows.append({"Örnek No": idx+1, "Sınıf": label, "Global T": None, "Otsu T": None})
        continue

    if img.dtype != np.uint8:
        img = img.astype(np.uint8)

    gT = global_threshold_T(img)
    oT = otsu_threshold_T(img)
    sk = skimage_thresholds(img)

    row = {
        "Örnek No": idx + 1,
        "Sınıf": label,
        "Global T": gT,
        "Otsu T": oT,
    }

    # skimage çoklu yöntemleri ayrı kolonlara aç
    for k, v in sk.items():
        row[f"sk_{k} T"] = (None if (v is None or np.isnan(v)) else f"{v:.2f}")

    rows.append(row)

threshold_df = pd.DataFrame(rows)

# Kolon sıralamasını daha okunur yap
base_cols = ["Örnek No", "Sınıf", "Global T", "Otsu T"]
sk_cols = [c for c in threshold_df.columns if c.startswith("sk_")]
threshold_df = threshold_df[base_cols + sorted(sk_cols)]

display(threshold_df)

"""## 3.2 Binary Görüntü Üretimi ve Yöntem Seçimi"""

import numpy as np
import matplotlib.pyplot as plt

def plot_masks_3col(masks, title_prefix="", labels=None, dpi=200):
    """
    masks: len=9 list (uint8 0/255)
    3x3 grid
    """
    if len(masks) != 9:
        raise ValueError(f"masks len=9 olmalı, şu an: {len(masks)}")

    fig, axes = plt.subplots(3, 3, figsize=(12, 10), dpi=dpi, constrained_layout=True)
    axes = axes.ravel()

    for i in range(9):
        ax = axes[i]
        ax.axis("off")

        m = masks[i]
        if m is None:
            ax.set_title(f"Ö{i+1} {title_prefix}\n(None)", fontsize=10)
            continue

        lab = "" if labels is None else f"\n{labels[i]}"
        ax.imshow(m, cmap="gray", vmin=0, vmax=255)
        ax.set_title(f"Ö{i+1} {title_prefix}{lab}", fontsize=10)

    plt.show()

"""##Global Threshold Maskeleri"""

col = "Global T"
if col not in mask_df.columns:
    raise KeyError(f"mask_df içinde '{col}' yok. Mevcut sütunlar: {list(mask_df.columns)}")

global_masks = [make_binary_mask(median_imgs[i], mask_df.loc[i, col]) for i in range(9)]
plot_masks_3col(global_masks, title_prefix="GlobalMask", labels=labels)

"""##Otsu Maskeleri"""

col = "Otsu T"
if col not in mask_df.columns:
    raise KeyError(f"mask_df içinde '{col}' yok. Mevcut sütunlar: {list(mask_df.columns)}")

otsu_masks = [make_binary_mask(median_imgs[i], mask_df.loc[i, col]) for i in range(9)]
plot_masks_3col(otsu_masks, title_prefix="OtsuMask", labels=labels)

"""##Sk_isodata Maskeleri"""

col = "sk_isodata T"
if col not in mask_df.columns:
    raise KeyError(f"mask_df içinde '{col}' yok. Mevcut sütunlar: {list(mask_df.columns)}")

iso_masks = [make_binary_mask(median_imgs[i], mask_df.loc[i, col]) for i in range(9)]
plot_masks_3col(iso_masks, title_prefix="IsodataMask", labels=labels)

"""##Skimage Li Maskeleri"""

col = "sk_li T"
if col not in mask_df.columns:
    raise KeyError(f"mask_df içinde '{col}' yok. Mevcut sütunlar: {list(mask_df.columns)}")

li_masks = [make_binary_mask(median_imgs[i], mask_df.loc[i, col]) for i in range(9)]
plot_masks_3col(li_masks, title_prefix="LiMask", labels=labels)

"""##Skimage Mean Maskeleri"""

col = "sk_mean T"
if col not in mask_df.columns:
    raise KeyError(f"mask_df içinde '{col}' yok. Mevcut sütunlar: {list(mask_df.columns)}")

mean_masks = [make_binary_mask(median_imgs[i], mask_df.loc[i, col]) for i in range(9)]
plot_masks_3col(mean_masks, title_prefix="MeanMask", labels=labels)

"""##Skimage Minimum Maskeleri (SEÇİLEN)"""

col = "sk_minimum T"
if col not in mask_df.columns:
    raise KeyError(f"mask_df içinde '{col}' yok. Mevcut sütunlar: {list(mask_df.columns)}")

min_masks = [make_binary_mask(median_imgs[i], mask_df.loc[i, col]) for i in range(9)]
plot_masks_3col(min_masks, title_prefix="MinimumMask", labels=labels)

"""##Skimage Triangle Maskeleri"""

col = "sk_triangle T"
if col not in mask_df.columns:
    raise KeyError(f"mask_df içinde '{col}' yok. Mevcut sütunlar: {list(mask_df.columns)}")

tri_masks = [make_binary_mask(median_imgs[i], mask_df.loc[i, col]) for i in range(9)]
plot_masks_3col(tri_masks, title_prefix="TriangleMask", labels=labels)

"""##Skimage Yen Maskeleri"""

col = "sk_yen T"
if col not in mask_df.columns:
    raise KeyError(f"mask_df içinde '{col}' yok. Mevcut sütunlar: {list(mask_df.columns)}")

yen_masks = [make_binary_mask(median_imgs[i], mask_df.loc[i, col]) for i in range(9)]
plot_masks_3col(yen_masks, title_prefix="YenMask", labels=labels)

"""### En Uygun Thresholding Yöntemi Seçimi

Bu çalışmada “en uygun” thresholding yöntemi olarak **Minimum Thresholding (`skimage.filters.threshold_minimum`)** seçtim.

**Seçim kriterim** (sınır bütünlüğü, gürültü miktarı, ROI’nin kopması/taşması) şu şekildeydi:

- **ROI taşmasını daha iyi kontrol etti:** Global/Otsu/Li/Yen yöntemlerinde bazı örneklerde arka plan geniş alanlar halinde maske içine girerek **taşma (spill/overflow)** oluşturdu. Minimum yöntemi daha kontrollü kaldı.
- **Gürültüyü daha düşük tuttu:** Saç/deri dokusu ve aydınlatma heterojenliği kaynaklı piksellerin maske içine “gürültü” olarak karışması Minimum’da daha sınırlıydı.
- **Sınır bütünlüğü daha tutarlıydı:** Minimum yöntemi genel olarak lezyon sınırını daha stabil korudu. Triangle bazı örneklerde iyi görünse de diğer örneklerde **aşırı geniş ROI** üreterek sınırları bozabildi.
- **ROI kopması daha yönetilebilirdi:** Minimum bazı örneklerde parçalanmalar üretebilse de bu durum sonraki adımda basit post-process (küçük bileşen temizliği / en büyük bağlı bileşen seçimi) ile toparlanabilir. Buna karşın taşma problemi daha kritik olduğu için önceliğim taşmayı azaltmaktı.

Bu nedenle, genel örnekler üzerinde en dengeli sonucu verdiği için **Minimum Thresholding** ile devam etmeyi tercih ettim.

# 4) Post-Processing

## 4.1 Morfolojik Operatörler

##Erosion
"""

import numpy as np
import matplotlib.pyplot as plt
import cv2

# ---------- Guard ----------
if "median_imgs" not in globals():
    raise NameError("median_imgs bulunamadı. Girdi olarak stretch+median sonrası 9 görüntü gerekiyor.")
if "mask_df" not in globals():
    raise NameError("mask_df bulunamadı. 3.1 eşik tablon (DataFrame) mask_df olarak hazır olmalı.")
if len(median_imgs) != 9 or len(mask_df) != 9:
    raise ValueError("median_imgs ve mask_df 9 örnek içermeli.")

# ---------- Threshold kolonu bul (sende: 'sk_minimum T') ----------
candidates = ["sk_minimum T", "sk_minimum_T", "Minimum T", "minimum_T", "minimum T"]
TH_COL = next((c for c in candidates if c in mask_df.columns), None)
if TH_COL is None:
    raise KeyError(f"Minimum threshold kolonu bulunamadı. Mevcut sütunlar: {list(mask_df.columns)}")
print("✅ Kullanılan threshold kolonu:", TH_COL)

labels = mask_df["Sınıf"].tolist() if "Sınıf" in mask_df.columns else [""] * 9
thresholds = mask_df[TH_COL].tolist()

# ---------- Binary mask (lezyon koyu => <=T) ----------
def make_binary_mask(gray_u8, T):
    img = gray_u8.astype(np.uint8)
    T = float(T)
    return ((img <= T).astype(np.uint8) * 255).astype(np.uint8)  # lesion=255

def make_kernel(shape="ellipse", ksize=5):
    ksize = int(ksize)
    if ksize % 2 == 0:
        ksize += 1
    if shape == "ellipse":
        return cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (ksize, ksize))
    if shape == "rect":
        return cv2.getStructuringElement(cv2.MORPH_RECT, (ksize, ksize))
    if shape == "cross":
        return cv2.getStructuringElement(cv2.MORPH_CROSS, (ksize, ksize))
    raise ValueError("shape 'ellipse' | 'rect' | 'cross' olmalı.")

# ---------- Ayarlanabilir Erosion Parametreleri ----------
ERODE_KERNEL_SHAPE = "ellipse"
ERODE_KSIZE = 4    # <-- BUNU DEĞİŞTİR
ERODE_ITER  = 3    # <-- BUNU DEĞİŞTİR

kernel_e = make_kernel(ERODE_KERNEL_SHAPE, ERODE_KSIZE)

# ---------- Üret: Binary + Erosion ----------
binary_masks = [make_binary_mask(median_imgs[i], thresholds[i]) for i in range(9)]
eroded_masks = [cv2.erode(binary_masks[i], kernel_e, iterations=int(ERODE_ITER)) for i in range(9)]

# ---------- Plot: dilation hücresindeki ile AYNI yapı (3x3, her hücrede yan yana) ----------
def plot_pair_grid(left_masks, right_masks, labels=None, title_prefix="MinimumMask", left_name="Binary (<=T)", right_name="Erosion"):
    fig, axes = plt.subplots(3, 3, figsize=(11.69, 8.27), dpi=250)
    axes = np.array(axes).reshape(3, 3)

    for i in range(9):
        r, c = divmod(i, 3)
        ax = axes[r, c]
        ax.axis("off")

        if left_masks[i] is None or right_masks[i] is None:
            ax.set_title(f"Ö{i+1} | missing", fontsize=9, pad=2)
            continue

        pair = np.concatenate([left_masks[i], right_masks[i]], axis=1)
        lab = "" if labels is None else labels[i]
        ax.imshow(pair, cmap="gray", vmin=0, vmax=255, interpolation="nearest", aspect="auto")
        ax.set_title(f"Ö{i+1} | {title_prefix}\n{left_name} | {right_name}\n{lab}", fontsize=9, pad=2)

    plt.tight_layout(pad=0.8)
    plt.show()

plot_pair_grid(
    binary_masks,
    eroded_masks,
    labels=labels,
    title_prefix=f"MinimumMask | Erosion(k={ERODE_KSIZE}, iter={ERODE_ITER}, {ERODE_KERNEL_SHAPE})",
    left_name="Binary (<=T)",
    right_name="Erosion"
)

print("\n--- Erosion ayarları ---")
print(f"Kernel: {ERODE_KERNEL_SHAPE}, ksize={ERODE_KSIZE}, iter={ERODE_ITER}")

# pipeline devamı için RAM'de:
# binary_masks, eroded_masks

"""##Dilatasyon"""

import numpy as np
import matplotlib.pyplot as plt
import cv2

# ---------------------------
# Guard
# ---------------------------
if "eroded_masks" not in globals():
    raise NameError("eroded_masks bulunamadı. Önce Erosion hücresini çalıştırıp eroded_masks üretmelisin.")
if len(eroded_masks) != 9:
    raise ValueError(f"eroded_masks uzunluğu {len(eroded_masks)}. len=9 olmalı.")

# labels (opsiyonel)
labels = None
if "mask_df" in globals() and ("Sınıf" in mask_df.columns) and len(mask_df) == 9:
    labels = mask_df["Sınıf"].tolist()

# ---------------------------
# Dilation params (sen ayarlayacaksın)
# ---------------------------
KERNEL_SHAPE = "ellipse"   # "ellipse" | "rect"
KSIZE = 4
ITER  = 4

def make_kernel(shape="ellipse", ksize=3):
    if shape == "rect":
        return cv2.getStructuringElement(cv2.MORPH_RECT, (ksize, ksize))
    return cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (ksize, ksize))

def apply_dilation(mask_u8, kernel, iters=1):
    m = mask_u8.astype(np.uint8)
    return cv2.dilate(m, kernel, iterations=iters)

# ---------------------------
# Apply dilation AFTER erosion (pipeline)
# ---------------------------
kernel = make_kernel(KERNEL_SHAPE, KSIZE)
dilated_masks = [apply_dilation(m, kernel, ITER) for m in eroded_masks]

print("--- Dilation ayarları ---")
print(f"Kernel: {KERNEL_SHAPE}, ksize={KSIZE}, iter={ITER}")

# ---------------------------
# Plot: 3x3, (Erosion | Dilation)
# (senin verdiğin fonksiyon yapısına birebir uyumlu)
# ---------------------------
def plot_pair_grid(left_masks, right_masks, labels=None, title_prefix="PostMask", right_name="Dilation"):
    fig, axes = plt.subplots(3, 3, figsize=(11.69, 8.27), dpi=250)
    axes = np.array(axes).reshape(3, 3)

    for i in range(9):
        r, c = divmod(i, 3)
        ax = axes[r, c]
        ax.axis("off")

        if left_masks[i] is None or right_masks[i] is None:
            ax.set_title(f"Ö{i+1} | missing", fontsize=9, pad=2)
            continue

        pair = np.concatenate([left_masks[i], right_masks[i]], axis=1)
        lab = "" if labels is None else labels[i]
        ax.imshow(pair, cmap="gray", vmin=0, vmax=255, interpolation="nearest", aspect="auto")
        ax.set_title(f"Ö{i+1} | {title_prefix}\nErosion | {right_name}\n{lab}", fontsize=9, pad=2)

    plt.tight_layout(pad=0.8)
    plt.show()

# çağır
plot_pair_grid(
    left_masks=eroded_masks,
    right_masks=dilated_masks,
    labels=labels,
    title_prefix=f"Dilation(k={KSIZE}, iter={ITER}, {KERNEL_SHAPE})",
    right_name="Dilation"
)

# pipeline devamı için:
# - eroded_masks (input)
# - dilated_masks (output)

"""##Hole Filling"""

import numpy as np
import cv2
import matplotlib.pyplot as plt

# ---------- Guard ----------
if "dilated_masks" not in globals():
    raise NameError("dilated_masks bulunamadı. Bu hücreyi dilation hücresinden sonra çalıştırmalısın.")
if len(dilated_masks) != 9:
    raise ValueError(f"dilated_masks uzunluğu {len(dilated_masks)}. len=9 olmalı.")

def fill_holes_by_cc(mask_u8, max_hole_ratio=0.30):
    """
    Hole filling (robust):
    - Hole = background component that does NOT touch image border.
    - Prevents 'patlama' when foreground touches border.
    max_hole_ratio: doldurulacak hole alanı, foreground alanının bu oranını aşarsa skip (güvenlik).
    """
    m = mask_u8.astype(np.uint8).copy()

    # 0/255 değilse normalize etmeye çalış
    m = np.where(m > 0, 255, 0).astype(np.uint8)

    fg_area = int((m == 255).sum())
    if fg_area == 0:
        return m  # boş maske

    # background: 1, foreground: 0
    bg = (m == 0).astype(np.uint8)

    num, lab = cv2.connectedComponents(bg, connectivity=8)

    if num <= 1:
        # background tek bileşen -> delik yok
        return m

    # border'a dokunan background label'ları bul
    border_labels = set()
    border_labels.update(np.unique(lab[0, :]).tolist())
    border_labels.update(np.unique(lab[-1, :]).tolist())
    border_labels.update(np.unique(lab[:, 0]).tolist())
    border_labels.update(np.unique(lab[:, -1]).tolist())

    # hole: border'a dokunmayan label'lar (0 arka planın label'ı olabilir, zaten border'dadır)
    hole_mask = np.zeros_like(m, dtype=np.uint8)
    for k in range(1, num):
        if k not in border_labels:
            hole_mask[lab == k] = 255

    hole_area = int((hole_mask == 255).sum())

    # Güvenlik: delik alanı aşırı büyürse patlamayı önle (ör: threshold hatası)
    if hole_area > int(max_hole_ratio * fg_area):
        return m

    # delikleri doldur
    m[hole_mask == 255] = 255
    return m

filled_masks = [fill_holes_by_cc(m, max_hole_ratio=0.30) for m in dilated_masks]

# ---------- Plot: 3x3 (Dilation | HoleFill) ----------
def plot_pair_grid(left_masks, right_masks, labels=None,
                   title_prefix="MinimumMask", left_name="Dilation", right_name="HoleFill"):
    fig, axes = plt.subplots(3, 3, figsize=(11.69, 8.27), dpi=250)
    axes = np.array(axes).reshape(3, 3)

    for i in range(9):
        r, c = divmod(i, 3)
        ax = axes[r, c]
        ax.axis("off")

        pair = np.concatenate([left_masks[i], right_masks[i]], axis=1)
        labtxt = "" if labels is None else labels[i]
        ax.imshow(pair, cmap="gray", vmin=0, vmax=255, interpolation="nearest", aspect="auto")
        ax.set_title(f"Ö{i+1} | {title_prefix}\n{left_name} | {right_name}\n{labtxt}", fontsize=9, pad=2)

    plt.tight_layout(pad=0.8)
    plt.show()

try:
    labels = mask_df["Sınıf"].tolist()
except Exception:
    labels = None

plot_pair_grid(dilated_masks, filled_masks, labels=labels,
               title_prefix="MinimumMask", left_name="Dilation", right_name="HoleFill")

print("✅ Hole filling: connected-components (border-touch rule) yöntemi uygulandı.")
print("Param: max_hole_ratio=0.30 (delik alanı fg'nin %30'unu aşarsa doldurma yapılmaz)")

# pipeline devamı:
# filled_masks

"""Bu aşamada amaç; threshold sonrası oluşan **saç/toz benzeri küçük gürültüleri azaltmak**, ROI’nin sınırlarını daha **bütün ve okunur** hâle getirmek ve ROI içinde oluşabilecek **küçük boşlukları** kontrollü şekilde düzeltmektir. Bu nedenle şu operatör dizisini kullandım:

### Seçilen operatör(ler) ve gerekçesi
- **Erosion → Dilation (Opening benzeri etki)**  
  Erosion ile ince çizgiler, küçük noktalar ve “hair-like” artefaktlar bastırıldı. Ardından Dilation ile ROI’nin erosion ile kaybettiği alanın **kontrollü biçimde geri kazanılması** sağlandı. Bu ikili, gürültüyü azaltırken ROI’yi tamamen erozyona uğratmadan korumak için dengeli bir yaklaşımdır.
- **Hole Filling (yalnızca gerçek “iç boşluklar” için, güvenlikli)**  
  Dilation sonrası ROI içinde kalan küçük boşlukları düzeltmek için hole filling eklendi. Ancak klasik flood-fill yaklaşımı bazı örneklerde (özellikle ROI sınırla temas edince) taşmaya yol açabildiği için, hole filling işlemi **“sınırla temas etmeyen arka plan bileşenlerini delik kabul etme”** mantığıyla sınırlandırıldı. Böylece ROI dışındaki arka planın yanlışlıkla doldurulması engellendi.

### Kernel şekli ve boyutu neden böyle seçildi?
- **Kernel şekli: ellipse (disk benzeri)**
  Lezyonların morfolojisi çoğunlukla köşeli değil, daha organik/yuvarlatılmış yapıda olduğu için eliptik kernel; ROI’nin doğal sınır geometrisini daha iyi korurken, ince gürültüleri daha etkili bastırır.
- **Kernel boyutu ve iterasyon**
  Kernel boyutu/iterasyon değerleri “gürültü bastırma ↔ ROI korunumu” dengesi gözetilerek seçildi. Çok küçük kernel gürültüyü yeterince temizlemezken, çok büyük kernel ROI’yi aşırı inceltip kopmalara neden olabilir. Bu yüzden parametreleri örnekler üzerinde görsel kontrol ederek ROI kopması/taşması olmadan gürültüyü azaltacak aralıkta tuttum.

### Gürültüyü azaltırken ROI’yi nasıl korudum?
- **Önce erosion ile küçük parçaları hedefledim:** saç/toz gibi ince detaylar erosion ile hızla kaybolurken, ana ROI kütlesi daha dayanıklı kaldı.
- **Ardından dilation ile ROI’yi geri toparladım:** erosion’un ROI üzerinde oluşturabileceği daralmayı telafi ederek, ana lezyon bölgesinin bütünlüğünü korudum.
- **Hole filling’i kontrollü uyguladım:** sadece ROI içindeki gerçek boşlukları dolduracak şekilde (sınırla temas etmeyen arka plan bileşenleri) çalıştırarak, ROI’nin arka plana taşmasını engelledim.
- **Görsel doğrulama:** 9 örnek üzerinde “Binary → Erosion → Dilation → HoleFill” çıktıları yan yana incelenerek, gürültü azalırken ROI sınırlarının korunup korunmadığı kontrol edildi.

## 4.2 Connected Component Labeling – CCL
"""

import numpy as np
import matplotlib.pyplot as plt
import cv2

# ---------- Guard ----------
if "filled_masks" not in globals():
    raise NameError("filled_masks bulunamadı. 4.1 morfoloji+holefill sonrası 9 maske (uint8, 0/255) gerekir.")
if len(filled_masks) != 9:
    raise ValueError("filled_masks 9 örnek içermeli (n=9).")

labels = globals().get("labels", [""] * 9)
if labels is None or len(labels) != 9:
    labels = [""] * 9

# ---------- Helpers ----------
def ensure_bin_u8(mask_u8):
    """0/255 uint8 binary maske garantisi."""
    m = (mask_u8 > 0).astype(np.uint8) * 255
    return m.astype(np.uint8)

def label_to_color(label_map):
    """
    label_map: int32 [H,W], 0=bg, 1..K=components
    çıktı: RGB uint8 [H,W,3]
    """
    h, w = label_map.shape
    out = np.zeros((h, w, 3), dtype=np.uint8)
    # sabit, okunabilir bir palette (cv2 applyColorMap değil, deterministic)
    rng = np.random.default_rng(12345)
    K = int(label_map.max())
    if K <= 0:
        return out
    colors = rng.integers(30, 255, size=(K + 1, 3), dtype=np.uint8)
    colors[0] = 0  # background siyah
    out = colors[label_map]
    return out

def plot_rgb_grid(rgb_imgs, labels=None, title_prefix="CCL Labels", figsize=(11.69, 8.27), dpi=250):
    fig, axes = plt.subplots(3, 3, figsize=figsize, dpi=dpi)
    axes = np.array(axes).reshape(3, 3)

    for i in range(9):
        r, c = divmod(i, 3)
        ax = axes[r, c]
        ax.axis("off")
        ax.imshow(rgb_imgs[i], interpolation="nearest")
        lab = "" if labels is None else labels[i]
        ax.set_title(f"Ö{i+1} | {title_prefix}\n{lab}", fontsize=9, pad=2)

    plt.tight_layout(pad=0.8)
    plt.show()

def summarize_counts(counts, title="CCL dağılım özeti"):
    counts = list(map(int, counts))
    n = len(counts)
    z0 = sum(1 for x in counts if x == 0)
    z1 = sum(1 for x in counts if x == 1)
    z2p = sum(1 for x in counts if x >= 2)
    print(f"# --- {title} (bg hariç) ---")
    print(f"Toplam görüntü: {n}")
    print(f"0 bileşen (ROI yok): {z0}")
    print(f"1 bileşen (ideal/hedef): {z1}")
    print(f"2+ bileşen: {z2p}")

def ccl_counts(mask_u8):
    """bg hariç bileşen sayısı"""
    m = ensure_bin_u8(mask_u8)
    num_labels, _ = cv2.connectedComponents(m, connectivity=8)
    return int(num_labels - 1)

# ---------- Strategy: Center-prior selection ----------
# Parametreler: sen oynayabil diye açık yazıyorum
MIN_AREA_PX = 300          # küçük gürültü bileşenlerini eler
LAMBDA_CENTER = 0.003      # merkeze uzaklık cezası (piksel başına)
KEEP_LARGEST_ONLY = False  # True yaparsan sadece max-area seçer (center-prior devre dışı kalır)

def pick_component_center_prior(stats, centroids, img_center, min_area_px=300, lam=0.003, keep_largest_only=False):
    """
    stats: (K+1,5) -> [x,y,w,h,area], index 0 = bg
    centroids: (K+1,2)
    img_center: (cx,cy)
    """
    K = stats.shape[0] - 1
    if K <= 0:
        return None  # hiçbir bileşen yok

    # adaylar: area >= min_area
    candidates = []
    for lbl in range(1, K + 1):
        area = float(stats[lbl, cv2.CC_STAT_AREA])
        if area < float(min_area_px):
            continue
        cx, cy = centroids[lbl]
        dx = float(cx - img_center[0])
        dy = float(cy - img_center[1])
        dist = (dx * dx + dy * dy) ** 0.5

        if keep_largest_only:
            score = area
        else:
            # center-prior: alan büyük olsun, ama merkeze yakın olan avantajlı
            score = area - lam * dist * area  # alanla ölçeklenmiş ceza (robust)
            # Alternatif istersen:
            # score = area / (1.0 + lam * dist)

        candidates.append((score, lbl, area, dist))

    if not candidates:
        return None

    candidates.sort(key=lambda x: x[0], reverse=True)
    best = candidates[0]
    return best  # (score, label, area, dist)

# ---------- 1) CCL (strateji öncesi) ----------
filled_masks = [ensure_bin_u8(m) for m in filled_masks]

raw_label_maps = []
ccl_raw_label_imgs = []
comp_counts_raw = []

print("# --- CCL (strateji öncesi) bileşen sayıları (bg hariç) ---")
for i in range(9):
    m = filled_masks[i]
    num_labels, label_map = cv2.connectedComponents(m, connectivity=8)
    k = int(num_labels - 1)
    comp_counts_raw.append(k)

    print(f"Ö{i+1}: {k} bileşen | {labels[i]}")
    raw_label_maps.append(label_map)
    ccl_raw_label_imgs.append(label_to_color(label_map))

summarize_counts(comp_counts_raw, title="CCL dağılım özeti (strateji öncesi, n=9)")

plot_rgb_grid(ccl_raw_label_imgs, labels=labels, title_prefix="CCL Labels (raw)")

# ---------- 2) Center-prior strateji uygula: tek ROI seç ----------
selected_masks = []         # her görüntü için tek-ROI binary (0/255)
after_label_maps = []       # strateji sonrası label_map (0/1)
ccl_after_label_imgs = []
comp_counts_after = []      # strateji sonrası bileşen sayısı (hedef 1)

print("\n# --- Center-prior strateji (en uygun ROI seçimi) ---")
for i in range(9):
    m = filled_masks[i]
    h, w = m.shape[:2]
    center = (w / 2.0, h / 2.0)

    # With stats (daha iyi seçim için)
    num_labels, label_map, stats, centroids = cv2.connectedComponentsWithStats(m, connectivity=8)

    best = pick_component_center_prior(
        stats=stats,
        centroids=centroids,
        img_center=center,
        min_area_px=MIN_AREA_PX,
        lam=LAMBDA_CENTER,
        keep_largest_only=KEEP_LARGEST_ONLY
    )

    if best is None:
        # aday yoksa (ya hiç komponent yok ya da hepsi min_area altında)
        sel = np.zeros_like(m, dtype=np.uint8)
        comp_counts_after.append(0)
        print(f"Ö{i+1}: Uygun aday yok (min_area={MIN_AREA_PX}) | {labels[i]}")
    else:
        score, lbl, area, dist = best
        sel = (label_map == int(lbl)).astype(np.uint8) * 255
        comp_counts_after.append(1)
        print(f"Ö{i+1}: seçilen label={lbl} | area={int(area)} | dist_to_center={dist:.1f} | {labels[i]}")

    selected_masks.append(sel)

    # strateji sonrası label_map (0/1) üretip renklendir
    after_map = (sel > 0).astype(np.int32)  # 0 bg, 1 ROI
    after_label_maps.append(after_map)
    ccl_after_label_imgs.append(label_to_color(after_map))

summarize_counts(comp_counts_after, title="CCL dağılım özeti (strateji sonrası, n=9)")

plot_rgb_grid(ccl_after_label_imgs, labels=labels, title_prefix="CCL Labels (after: center-prior ROI)")

print("\n--- Strateji Parametreleri ---")
print(f"MIN_AREA_PX = {MIN_AREA_PX}")
print(f"LAMBDA_CENTER = {LAMBDA_CENTER}")
print(f"KEEP_LARGEST_ONLY = {KEEP_LARGEST_ONLY}")

# Pipeline için RAM'de:
# filled_masks (girdi), ccl_raw_label_imgs, comp_counts_raw,
# selected_masks (tek ROI), comp_counts_after

"""- **Sonuç (strateji sonrası):** Uyguladığım center-prior seçim stratejisi ile **9/9 görüntüde tek ROI** elde ettim.  
  Dağılım özeti de bunu doğruluyor: **0 bileşen = 0**, **1 bileşen = 9**, **2+ bileşen = 0** (arka plan hariç).

- **Neden bu strateji? (1 ROI hedefi):**
  Morfoloji + hole filling sonrası bazı görüntülerde ROI dışı parçalar (saç/toz, kenar taşmaları, kırpılmamış artefaktlar) ayrı bileşenler oluşturuyordu.  
  Bu yüzden CCL’den çıkan bileşenler arasından **ROI olma olasılığı en yüksek** olanı seçmek zorundaydım.

- **Seçim kriterim (ROI seçimi):**
  1. **Alan (area) önceliği:** ROI genellikle en büyük veya büyük bileşenlerden biridir.  
  2. **Merkeze yakınlık (center-prior):** Dermoskopik görüntülerde lezyon çoğu zaman **kadranın merkezine yakın** konumlanır; kenara yakın taşmalar/artefaktlar bu kriterle elenir.  
  3. **Minimum alan filtresi (`MIN_AREA_PX`):** Çok küçük bileşenler çoğunlukla **gürültü** olduğu için seçimden önce elendi.

- **Gözlenen iyileşme:**
  - “raw” CCL görüntülerinde çoklu bileşen görülürken (gürültü + parçalanmış ROI), strateji sonrası maskelerde **tek parça, temiz bir ROI** elde edildi.
  - Görsellerde ROI’nin kenarları korunurken, küçük parçaların etkisi belirgin şekilde azaldı.

- **Not / Dikkat:**
  Bu yöntem “tek ROI” hedefi için uygun; ancak bazı örneklerde lezyon gerçekten iki ayrı parça gibi görünüyorsa (gerçek parçalanma), center-prior seçimi **tek parçayı** bırakır.  
  Böyle bir durumda birleştirme gerekiyorsa, CCL öncesi **closing** veya CCL sonrası **yakın bileşenleri birleştirme** gibi ek strateji tercih edebilirim.

# 5) Öznitelik (Feature) Çıkarımı

## 5.1 First-Order (İstatistiksel) Özellikler
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.stats import skew, kurtosis

# ---------- Guard ----------
if "median_imgs" not in globals():
    raise NameError("median_imgs bulunamadı. (stretch+median sonrası 9 görüntü listesi olmalı)")
if "selected_masks" not in globals():
    raise NameError("selected_masks bulunamadı. (CCL sonrası nihai ROI maskeleri listesi olmalı)")
if len(median_imgs) != 9 or len(selected_masks) != 9:
    raise ValueError(f"median_imgs={len(median_imgs)}, selected_masks={len(selected_masks)}. İkisi de len=9 olmalı.")

# labels opsiyonel (mask_df varsa al)
labels = None
if "mask_df" in globals() and isinstance(mask_df, pd.DataFrame) and ("Sınıf" in mask_df.columns) and (len(mask_df) == 9):
    labels = mask_df["Sınıf"].tolist()
else:
    labels = [""] * 9

# ---------- Helpers ----------
def _entropy_from_counts(counts):
    """Shannon entropy (base2) from histogram counts (non-negative)."""
    total = counts.sum()
    if total <= 0:
        return 0.0
    p = counts[counts > 0] / total
    return float(-(p * np.log2(p)).sum())

def first_order_features(gray_u8, roi_mask_u8, bins=256):
    """
    gray_u8: uint8 grayscale image (preprocessed)
    roi_mask_u8: uint8 mask, lesion=255, bg=0
    Returns dict of first-order features computed only within ROI.
    """
    if gray_u8 is None or roi_mask_u8 is None:
        return None

    img = gray_u8.astype(np.uint8)
    m = (roi_mask_u8.astype(np.uint8) > 0)

    roi_vals = img[m]
    if roi_vals.size == 0:
        # ROI yoksa NaN döndür
        return {
            "mean": np.nan, "std": np.nan, "variance": np.nan,
            "min": np.nan, "max": np.nan, "median": np.nan,
            "skewness": np.nan, "kurtosis": np.nan,
            "entropy": np.nan, "energy": np.nan,
            "roi_pixels": 0
        }

    v = roi_vals.astype(np.float32)

    # basic stats
    mu = float(np.mean(v))
    sd = float(np.std(v, ddof=0))
    var = float(np.var(v, ddof=0))
    vmin = int(np.min(roi_vals))
    vmax = int(np.max(roi_vals))
    vmed = float(np.median(v))

    # higher-order
    sk = float(skew(v, bias=True))
    ku = float(kurtosis(v, fisher=True, bias=True))  # Fisher: normal -> 0

    # histogram-based entropy / energy
    counts, _ = np.histogram(roi_vals, bins=bins, range=(0, 256))
    ent = _entropy_from_counts(counts)

    p = counts.astype(np.float64)
    p = p / (p.sum() + 1e-12)
    energy = float((p ** 2).sum())  # histogram energy

    return {
        "mean": mu,
        "std": sd,
        "variance": var,
        "min": vmin,
        "max": vmax,
        "median": vmed,
        "skewness": sk,
        "kurtosis": ku,
        "entropy": ent,
        "energy": energy,
        "roi_pixels": int(roi_vals.size)
    }

# ---------- Compute ----------
rows = []
for i in range(9):
    feats = first_order_features(median_imgs[i], selected_masks[i], bins=256)
    row = {
        "Örnek No": i + 1,
        "Sınıf": labels[i]
    }
    if feats is None:
        # güvenli fallback
        row.update({k: np.nan for k in ["mean","std","variance","min","max","median","skewness","kurtosis","entropy","energy","roi_pixels"]})
    else:
        row.update(feats)
    rows.append(row)

first_order_df = pd.DataFrame(rows)

# ---------- Display (DataFrame) ----------
display(first_order_df)

# ---------- Optional: Pretty Table Figure (A4-friendly) ----------
def show_table_as_figure(df, title="First-Order Features (ROI only)"):
    fig, ax = plt.subplots(figsize=(11.69, 8.27), dpi=200)
    ax.axis("off")
    ax.set_title(title, fontsize=12, pad=10)

    # yuvarlama
    df_show = df.copy()
    float_cols = df_show.select_dtypes(include=["float64","float32"]).columns
    df_show[float_cols] = df_show[float_cols].round(4)

"""## 5.2 2D Shape (Şekil) Özellikleri"""

# =========================
# 5.2 2D Shape (Şekil) Özellikleri
# Input: selected_masks (CCL sonrası nihai ROI maskesi, len=9, ROI=255, bg=0)
# Output: shape_df (tablo)
# =========================

import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt

# ---------- Guard ----------
if "selected_masks" not in globals():
    raise NameError("selected_masks bulunamadı. (CCL sonrası nihai ROI maskeleri listesi olmalı)")
if len(selected_masks) != 9:
    raise ValueError(f"selected_masks uzunluğu {len(selected_masks)}. len=9 olmalı.")

# labels opsiyonel (mask_df varsa al)
labels = None
if "mask_df" in globals() and isinstance(mask_df, pd.DataFrame) and ("Sınıf" in mask_df.columns) and (len(mask_df) == 9):
    labels = mask_df["Sınıf"].tolist()
else:
    labels = [""] * 9

# ---------- Helper ----------
def shape_features_from_mask(mask_u8):
    """
    mask_u8: uint8 binary mask, ROI=255, bg=0
    Returns dict of shape features computed from the largest contour.
    """
    if mask_u8 is None:
        return None

    m = (mask_u8.astype(np.uint8) > 0).astype(np.uint8) * 255
    if m.sum() == 0:
        return {
            "area": np.nan,
            "perimeter": np.nan,
            "circularity": np.nan,
            "eccentricity": np.nan,
            "solidity": np.nan,
            "extent": np.nan,
            "major_axis_length": np.nan,
            "minor_axis_length": np.nan,
            "aspect_ratio": np.nan,
            "convex_area": np.nan,
            "bbox_x": np.nan,
            "bbox_y": np.nan,
            "bbox_w": np.nan,
            "bbox_h": np.nan,
            "equivalent_diameter": np.nan
        }

    # contour(s)
    contours, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not contours:
        return {
            "area": np.nan, "perimeter": np.nan, "circularity": np.nan,
            "eccentricity": np.nan, "solidity": np.nan, "extent": np.nan,
            "major_axis_length": np.nan, "minor_axis_length": np.nan, "aspect_ratio": np.nan,
            "convex_area": np.nan, "bbox_x": np.nan, "bbox_y": np.nan, "bbox_w": np.nan, "bbox_h": np.nan,
            "equivalent_diameter": np.nan
        }

    # largest by area
    cnt = max(contours, key=cv2.contourArea)

    area = float(cv2.contourArea(cnt))
    peri = float(cv2.arcLength(cnt, True))

    # bounding box
    x, y, w, h = cv2.boundingRect(cnt)
    extent = float(area / (w * h + 1e-12))

    # convex hull / solidity
    hull = cv2.convexHull(cnt)
    convex_area = float(cv2.contourArea(hull))
    solidity = float(area / (convex_area + 1e-12))

    # circularity
    circularity = float(4.0 * np.pi * area / (peri * peri + 1e-12))

    # equivalent diameter
    eq_d = float(np.sqrt(4.0 * area / (np.pi + 1e-12)))

    # ellipse for major/minor axis & eccentricity (needs >=5 pts)
    major = minor = ecc = np.nan
    if len(cnt) >= 5:
        (cx, cy), (MA, ma), angle = cv2.fitEllipse(cnt)
        # OpenCV returns axes as full lengths
        major = float(max(MA, ma))
        minor = float(min(MA, ma))
        a = major / 2.0
        b = minor / 2.0
        if a > 1e-9:
            ecc = float(np.sqrt(max(0.0, 1.0 - (b*b)/(a*a + 1e-12))))

    aspect_ratio = float(w / (h + 1e-12))

    return {
        "area": area,
        "perimeter": peri,
        "circularity": circularity,
        "eccentricity": ecc,
        "solidity": solidity,
        "extent": extent,
        "major_axis_length": major,
        "minor_axis_length": minor,
        "aspect_ratio": aspect_ratio,
        "convex_area": convex_area,
        "bbox_x": int(x),
        "bbox_y": int(y),
        "bbox_w": int(w),
        "bbox_h": int(h),
        "equivalent_diameter": eq_d
    }

# ---------- Compute ----------
rows = []
for i in range(9):
    feats = shape_features_from_mask(selected_masks[i])
    row = {"Örnek No": i + 1, "Sınıf": labels[i]}
    if feats is None:
        row.update({k: np.nan for k in [
            "area","perimeter","circularity","eccentricity","solidity","extent",
            "major_axis_length","minor_axis_length","aspect_ratio","convex_area",
            "bbox_x","bbox_y","bbox_w","bbox_h","equivalent_diameter"
        ]})
    else:
        row.update(feats)
    rows.append(row)

shape_df = pd.DataFrame(rows)

# ---------- Display (DataFrame) ----------
display(shape_df)

# ---------- Optional: Pretty Table Figure (A4-friendly) ----------
def show_table_as_figure(df, title="Shape Features (Binary ROI mask)"):
    fig, ax = plt.subplots(figsize=(11.69, 8.27), dpi=200)
    ax.axis("off")
    ax.set_title(title, fontsize=12, pad=10)

    df_show = df.copy()
    float_cols = df_show.select_dtypes(include=["float64","float32"]).columns
    df_show[float_cols] = df_show[float_cols].round(4)

"""## 5.3 GLCM (Second-Order Texture) Özellikler"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from skimage.feature import graycomatrix, graycoprops
from scipy.stats import entropy as scipy_entropy

# =========================
# 5.3 GLCM (Second-Order Texture) Features (ROI-only)
# Input:
#   - median_imgs: list(len=9) uint8 grayscale (crop+stretch+median output)
#   - selected_masks: list(len=9) uint8 binary ROI mask (0/255)
# Output:
#   - glcm_df: DataFrame (9 satır)
# =========================

# ---------- Guard ----------
if "median_imgs" not in globals():
    raise NameError("median_imgs bulunamadı. Girdi olarak stretch+median sonrası 9 görüntü gerekiyor.")
if "selected_masks" not in globals():
    raise NameError("selected_masks bulunamadı. Girdi olarak nihai ROI maskeleri (len=9) gerekiyor.")
if len(median_imgs) != 9 or len(selected_masks) != 9:
    raise ValueError(f"median_imgs={len(median_imgs)}, selected_masks={len(selected_masks)}; ikisi de 9 olmalı.")

# ---------- GLCM Parametreleri (rapora yazılacak) ----------
GLCM_DISTANCES = [1, 2]
GLCM_ANGLES = [0, np.pi/4, np.pi/2, 3*np.pi/4]

# Quantization: 8/16/32 gibi. (Levels=16 iyi bir denge)
GLCM_LEVELS = 16

# ROI patch çıkarırken mask dışını dolduracağımız seviye (quantize sonrası 0)
FILL_VALUE = 0

# ---------- Helpers ----------
def quantize_u8(img_u8, levels=16):
    """uint8 (0..255) -> [0..levels-1] aralığına indirgeme"""
    img = img_u8.astype(np.uint8)
    if levels <= 1:
        return np.zeros_like(img, dtype=np.uint8)
    q = (img.astype(np.float32) * (levels - 1) / 255.0)
    return np.clip(np.round(q), 0, levels - 1).astype(np.uint8)

def roi_bbox_from_mask(mask_u8):
    """mask (0/255) -> bbox (y1,y2,x1,x2) ya da None"""
    ys, xs = np.where(mask_u8 > 0)
    if len(xs) == 0:
        return None
    y1, y2 = ys.min(), ys.max() + 1
    x1, x2 = xs.min(), xs.max() + 1
    return y1, y2, x1, x2

def glcm_features_roi(img_u8, mask_u8, distances, angles, levels=16, fill_value=0):
    """
    ROI içinde GLCM çıkarır.
    Strateji:
      1) ROI bbox patch al
      2) quantize et
      3) mask dışını fill_value yap
      4) graycomatrix -> props (ortalama)
    """
    img_u8 = img_u8.astype(np.uint8)
    mask_u8 = mask_u8.astype(np.uint8)

    bb = roi_bbox_from_mask(mask_u8)
    if bb is None:
        return {k: np.nan for k in ["contrast","dissimilarity","homogeneity","energy","correlation","ASM"]}

    y1, y2, x1, x2 = bb
    patch = img_u8[y1:y2, x1:x2]
    mpatch = (mask_u8[y1:y2, x1:x2] > 0).astype(np.uint8)

    # quantize
    qpatch = quantize_u8(patch, levels=levels)

    # mask dışını doldur
    qpatch_masked = qpatch.copy()
    qpatch_masked[mpatch == 0] = fill_value

    # GLCM
    glcm = graycomatrix(
        qpatch_masked,
        distances=distances,
        angles=angles,
        levels=levels,
        symmetric=True,
        normed=True
    )

    # props: her biri (len(distances), len(angles)) -> ortalama alıyoruz
    feats = {}
    feats["contrast"]      = float(np.mean(graycoprops(glcm, "contrast")))
    feats["dissimilarity"] = float(np.mean(graycoprops(glcm, "dissimilarity")))
    feats["homogeneity"]   = float(np.mean(graycoprops(glcm, "homogeneity")))
    feats["energy"]        = float(np.mean(graycoprops(glcm, "energy")))
    feats["correlation"]   = float(np.mean(graycoprops(glcm, "correlation")))
    feats["ASM"]           = float(np.mean(graycoprops(glcm, "ASM")))
    return feats

# ---------- Compute ----------
rows = []
for i in range(9):
    img = median_imgs[i]
    msk = selected_masks[i]

    if img is None or msk is None:
        rows.append({"Örnek No": i+1, "Sınıf": labels[i] if "labels" in globals() else "",
                     "contrast": np.nan, "dissimilarity": np.nan, "homogeneity": np.nan,
                     "energy": np.nan, "correlation": np.nan, "ASM": np.nan})
        continue

    feats = glcm_features_roi(
        img_u8=img,
        mask_u8=msk,
        distances=GLCM_DISTANCES,
        angles=GLCM_ANGLES,
        levels=GLCM_LEVELS,
        fill_value=FILL_VALUE
    )

    rows.append({
        "Örnek No": i+1,
        "Sınıf": labels[i] if "labels" in globals() else "",
        **feats
    })

glcm_df = pd.DataFrame(rows)

# Sütunları düzenle
cols = ["Örnek No", "Sınıf", "contrast", "dissimilarity", "homogeneity", "energy", "correlation", "ASM"]
glcm_df = glcm_df[cols]

display(glcm_df)

print("\n--- GLCM Parametreleri ---")
print("distances =", GLCM_DISTANCES)
print("angles    =", ["0", "π/4", "π/2", "3π/4"])
print("levels (quantization) =", GLCM_LEVELS)

"""## 5.4 Feature Tablosu ve Çıktıların Yorumlanması"""

import os
import numpy as np
import pandas as pd

import cv2
from scipy.stats import skew, kurtosis

from skimage.measure import label as sk_label
from skimage.measure import regionprops

from skimage.feature import graycomatrix, graycoprops

# =========================================================
# GUARD
# =========================================================
if "median_imgs" not in globals():
    raise NameError("median_imgs yok. (crop+stretch+median çıktısı olan 9 görüntü) gerekli.")
if "selected_masks" not in globals():
    raise NameError("selected_masks yok. (nihai ROI maskeleri) gerekli.")
if len(median_imgs) != len(selected_masks):
    raise ValueError(f"median_imgs ({len(median_imgs)}) ve selected_masks ({len(selected_masks)}) aynı uzunlukta olmalı.")

N = len(median_imgs)

# labels & image_id kaynağı:
# - Eğer random9_train_df / samples varsa oradan alır.
# - Yoksa labels listesi varsa onu kullanır.
if "random9_train_df" in globals():
    meta_df = random9_train_df.reset_index(drop=True).copy()
elif "samples" in globals():
    meta_df = samples.reset_index(drop=True).copy()
else:
    meta_df = pd.DataFrame({"file_path": [f"img_{i+1}" for i in range(N)]})

if "label" not in meta_df.columns:
    if "labels" in globals() and len(labels) == N:
        meta_df["label"] = labels
    else:
        meta_df["label"] = [""] * N

# image_id: dosya adından üret
def _to_image_id(fp):
    try:
        return os.path.basename(str(fp))
    except:
        return str(fp)

meta_df["image_id"] = meta_df["file_path"].apply(_to_image_id) if "file_path" in meta_df.columns else [f"img_{i+1}" for i in range(N)]
meta_df["Örnek No"] = np.arange(1, N+1)
meta_df["roi_id"] = 1  # bu aşamada hedef: 1 görüntü = 1 ROI

# =========================================================
# 1) FIRST-ORDER FEATURES (ROI içinden, median_imgs üzerinden)
# =========================================================
def first_order_features(img_u8, mask_u8):
    img = img_u8.astype(np.uint8)
    m = (mask_u8 > 0)
    vals = img[m].astype(np.float64)

    if vals.size == 0:
        return {
            "fo_mean": np.nan, "fo_std": np.nan, "fo_var": np.nan,
            "fo_min": np.nan, "fo_max": np.nan, "fo_median": np.nan,
            "fo_skewness": np.nan, "fo_kurtosis": np.nan,
            "fo_entropy": np.nan, "fo_energy": np.nan
        }

    fo_mean = float(np.mean(vals))
    fo_std  = float(np.std(vals, ddof=0))
    fo_var  = float(np.var(vals, ddof=0))
    fo_min  = float(np.min(vals))
    fo_max  = float(np.max(vals))
    fo_med  = float(np.median(vals))

    # skewness & kurtosis (fisher=True -> normalde 0)
    fo_skew = float(skew(vals, bias=False)) if vals.size > 2 else np.nan
    fo_kurt = float(kurtosis(vals, fisher=True, bias=False)) if vals.size > 3 else np.nan

    # entropy / energy: ROI histogram (256 bin)
    hist = np.bincount(vals.astype(np.uint8), minlength=256).astype(np.float64)
    p = hist / (hist.sum() + 1e-12)
    p_nz = p[p > 0]
    fo_ent = float(-(p_nz * np.log2(p_nz)).sum())
    fo_eng = float((p ** 2).sum())

    return {
        "fo_mean": fo_mean, "fo_std": fo_std, "fo_var": fo_var,
        "fo_min": fo_min, "fo_max": fo_max, "fo_median": fo_med,
        "fo_skewness": fo_skew, "fo_kurtosis": fo_kurt,
        "fo_entropy": fo_ent, "fo_energy": fo_eng
    }

# =========================================================
# 2) SHAPE FEATURES (Binary ROI maskesinden)
# =========================================================
def shape_features(mask_u8):
    m = (mask_u8 > 0).astype(np.uint8)
    if m.sum() == 0:
        return {
            "sh_area": np.nan, "sh_perimeter": np.nan,
            "sh_circularity": np.nan, "sh_eccentricity": np.nan,
            "sh_solidity": np.nan, "sh_extent": np.nan,
            "sh_major_axis": np.nan, "sh_minor_axis": np.nan,
            "sh_aspect_ratio": np.nan, "sh_convex_area": np.nan,
            "sh_bbox_w": np.nan, "sh_bbox_h": np.nan,
            "sh_equiv_diameter": np.nan
        }

    # regionprops için label
    lbl = sk_label(m, connectivity=2)
    props = regionprops(lbl)

    # (teorik olarak 1 ROI olmalı; birden fazlaysa en büyük alanı al)
    props.sort(key=lambda r: r.area, reverse=True)
    r = props[0]

    area = float(r.area)
    # perimeter: skimage perimeter bazen farklı tanımlar; burada cv2 kontur kullanarak daha stabil bir "çevre" alalım
    contours, _ = cv2.findContours((m*255).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
    if len(contours) == 0:
        perim = np.nan
    else:
        c = max(contours, key=cv2.contourArea)
        perim = float(cv2.arcLength(c, True))

    circularity = float((4*np.pi*area)/((perim**2)+1e-12)) if np.isfinite(perim) else np.nan

    ecc = float(r.eccentricity) if hasattr(r, "eccentricity") else np.nan
    sol = float(r.solidity) if hasattr(r, "solidity") else np.nan
    ext = float(r.extent) if hasattr(r, "extent") else np.nan

    maj = float(r.major_axis_length) if hasattr(r, "major_axis_length") else np.nan
    minax = float(r.minor_axis_length) if hasattr(r, "minor_axis_length") else np.nan
    ar = float(maj/(minax+1e-12)) if np.isfinite(maj) and np.isfinite(minax) else np.nan

    convex_area = float(r.convex_area) if hasattr(r, "convex_area") else np.nan
    eqd = float(r.equivalent_diameter) if hasattr(r, "equivalent_diameter") else np.nan

    # bbox: (min_row, min_col, max_row, max_col)
    minr, minc, maxr, maxc = r.bbox
    bbox_w = float(maxc - minc)
    bbox_h = float(maxr - minr)

    return {
        "sh_area": area, "sh_perimeter": perim,
        "sh_circularity": circularity, "sh_eccentricity": ecc,
        "sh_solidity": sol, "sh_extent": ext,
        "sh_major_axis": maj, "sh_minor_axis": minax,
        "sh_aspect_ratio": ar, "sh_convex_area": convex_area,
        "sh_bbox_w": bbox_w, "sh_bbox_h": bbox_h,
        "sh_equiv_diameter": eqd
    }

# =========================================================
# 3) GLCM FEATURES (ROI-only, median_imgs üzerinden)
# =========================================================
GLCM_DISTANCES = [1, 2]
GLCM_ANGLES = [0, np.pi/4, np.pi/2, 3*np.pi/4]
GLCM_LEVELS = 16
FILL_VALUE = 0

def quantize_u8(img_u8, levels=16):
    img = img_u8.astype(np.uint8)
    q = (img.astype(np.float32) * (levels - 1) / 255.0)
    return np.clip(np.round(q), 0, levels - 1).astype(np.uint8)

def roi_bbox_from_mask(mask_u8):
    ys, xs = np.where(mask_u8 > 0)
    if len(xs) == 0:
        return None
    y1, y2 = ys.min(), ys.max() + 1
    x1, x2 = xs.min(), xs.max() + 1
    return y1, y2, x1, x2

def glcm_features_roi(img_u8, mask_u8, distances, angles, levels=16, fill_value=0):
    bb = roi_bbox_from_mask(mask_u8)
    if bb is None:
        return {k: np.nan for k in ["glcm_contrast","glcm_dissimilarity","glcm_homogeneity","glcm_energy","glcm_correlation","glcm_ASM"]}

    y1, y2, x1, x2 = bb
    patch = img_u8[y1:y2, x1:x2].astype(np.uint8)
    mpatch = (mask_u8[y1:y2, x1:x2] > 0).astype(np.uint8)

    qpatch = quantize_u8(patch, levels=levels)
    qpatch[mpatch == 0] = fill_value

    glcm = graycomatrix(qpatch, distances=distances, angles=angles, levels=levels, symmetric=True, normed=True)

    return {
        "glcm_contrast":      float(np.mean(graycoprops(glcm, "contrast"))),
        "glcm_dissimilarity": float(np.mean(graycoprops(glcm, "dissimilarity"))),
        "glcm_homogeneity":   float(np.mean(graycoprops(glcm, "homogeneity"))),
        "glcm_energy":        float(np.mean(graycoprops(glcm, "energy"))),
        "glcm_correlation":   float(np.mean(graycoprops(glcm, "correlation"))),
        "glcm_ASM":           float(np.mean(graycoprops(glcm, "ASM"))),
    }

# =========================================================
# FEATURE TABLE (satır: görüntü/ROI, sütun: öznitelikler)
# =========================================================
rows = []
for i in range(N):
    img = median_imgs[i]
    msk = selected_masks[i]

    row = {
        "image_id": meta_df.loc[i, "image_id"],
        "label": meta_df.loc[i, "label"],
        "Örnek No": int(meta_df.loc[i, "Örnek No"]),
        "roi_id": int(meta_df.loc[i, "roi_id"]),
    }

    if img is None or msk is None:
        # boş satır
        rows.append(row)
        continue

    row.update(first_order_features(img, msk))
    row.update(shape_features(msk))
    row.update(glcm_features_roi(img, msk, GLCM_DISTANCES, GLCM_ANGLES, levels=GLCM_LEVELS, fill_value=FILL_VALUE))

    rows.append(row)

feature_df = pd.DataFrame(rows)

# Feature sayısı (metadata hariç)
META_COLS = {"image_id","label","Örnek No","roi_id"}
feature_cols = [c for c in feature_df.columns if c not in META_COLS]
n_features = len(feature_cols)

display(feature_df)

# =========================================================
# CSV KAYDET
# =========================================================
OUT_CSV = "feature_table.csv"
feature_df.to_csv(OUT_CSV, index=False)
print(f"\n✅ Feature tablosu CSV kaydedildi: {OUT_CSV}")

# =========================================================
# ÖZET RAPOR (hocanın istediği metrikler)
# =========================================================
total_images = feature_df["image_id"].nunique()
total_rois = len(feature_df)  # satır sayısı = ROI sayısı (bu tabloda satır=ROI)

roi_counts = feature_df.groupby("image_id")["roi_id"].count()
multi_roi_images = (roi_counts > 1).sum()
multi_roi_rows = int(roi_counts[roi_counts > 1].sum()) if multi_roi_images > 0 else 0

print("\n--- Özet ---")
print("Toplam görüntü sayısı:", total_images)
print("Toplam ROI sayısı:", total_rois)
print("Görüntü başına feature sayısı (sütun):", n_features)
print("Birden fazla ROI oluşan görüntü sayısı:", int(multi_roi_images))
print("Birden fazla ROI oluşan görüntülerde toplam satır sayısı:", multi_roi_rows)

# 1 görüntü = 1 ROI hedefinden sapma var mı?
if (roi_counts != 1).any():
    print("\n⚠️ 1 görüntü = 1 ROI hedefinden sapma var.")
    print(roi_counts[roi_counts != 1])
else:
    print("\n✅ 1 görüntü = 1 ROI hedefi bu tabloda sağlandı (n=9).")

print("\n--- GLCM Parametreleri (raporda belirtilecek) ---")
print("distances =", GLCM_DISTANCES)
print("angles    =", ["0", "π/4", "π/2", "3π/4"])
print("levels (quantization) =", GLCM_LEVELS)

"""Bu aşamada, segmentasyon sonucunda elde ettiğim **nihai ROI maskesi** üzerinden tüm görüntüler için öznitelikleri tek bir feature tablosunda topladım.  
Tabloda **satırlar görüntüyü (1 görüntü = 1 ROI)**, **sütunlar ise çıkarılan öznitelikleri** temsil etmektedir. Ayrıca her satıra `image_id` ve `label/class` bilgilerini ekledim. Elde edilen feature tablosunu `.csv` formatında dışa aktardım.

- **Toplam görüntü sayısı:** 9  
- **Toplam ROI sayısı:** 9  
- **Görüntü başına oluşan feature sayısı (sütun sayısı):** 29  

Bu deney setinde **“1 görüntü = 1 ROI”** hedefinden sapma gözlenmemiştir. Bu nedenle CCL kaynaklı çoklu bileşen problemi bu örneklemde tabloya yansımamıştır:
- **Birden fazla ROI oluşan görüntü sayısı:** 0  
- **Birden fazla ROI oluştuğunda oluşacak ek satır sayısı:** 0  

GLCM tabanlı doku öznitelikleri için kullandığım parametreler aşağıdaki gibidir:
- **distances:** `[1, 2]`  
- **angles:** `[0, π/4, π/2, 3π/4]`  
- **gri seviye indirgeme (quantization) seviyesi:** `16`

"""

# ============================================================
# FULL DATASET PIPELINE -> FEATURES CSV
# Uses: train_df[file_path, label]
# Output: feature_table_full.csv
# ============================================================

import os, math, warnings
import numpy as np
import pandas as pd
import cv2

from skimage import filters
from skimage.measure import label as sk_label, regionprops, perimeter as sk_perimeter
from skimage.feature import graycomatrix, graycoprops
from scipy.stats import skew, kurtosis

warnings.filterwarnings("ignore")

# -----------------------------
# Guard
# -----------------------------
if "train_df" not in globals():
    raise NameError("train_df bulunamadı. Lütfen file_path ve label içeren DataFrame'i (train_df) önce oluştur.")
need_cols = {"file_path", "label"}
if not need_cols.issubset(set(train_df.columns)):
    raise KeyError(f"train_df kolonları eksik. Gerekli: {need_cols}, Mevcut: {list(train_df.columns)}")

print("✅ train_df hazır:", train_df.shape)

# -----------------------------
# PIPELINE PARAMS (istediğinde buradan değiştir)
# -----------------------------
# Crop
CROP_BASE_TRIM = 0.045
CROP_MIN_TRIM  = 0.015
CROP_STEP      = 0.005
CROP_GAP_PX    = 22
CROP_DARK_Q    = 0.30

# Contrast stretch (adaptive)
STRETCH_SOFT       = (6, 99)
STRETCH_MID        = (5, 97)
STRETCH_AGGRESSIVE = (2, 98)
STRETCH_THR_FLAT   = 0.20
STRETCH_THR_MID    = 0.33

# Median blur
MEDIAN_K = 5

# Threshold
THRESH_FALLBACK = "triangle"  # minimum fail olursa: "triangle" veya "otsu"

# Morphology (senin seçtiğin çizgide)
ERODE_KERNEL_SHAPE = "ellipse"
ERODE_KSIZE = 4
ERODE_ITER  = 3

DILATE_KERNEL_SHAPE = "ellipse"
DILATE_KSIZE = 4
DILATE_ITER  = 4

HOLE_MAX_RATIO = 0.30

# CCL strategy (center-prior)
MIN_AREA_PX      = 300
LAMBDA_CENTER    = 0.003
KEEP_LARGEST_ONLY = False

# GLCM params (hocanın istediği)
GLCM_DISTANCES = [1, 2]
GLCM_ANGLES    = [0, np.pi/4, np.pi/2, 3*np.pi/4]
GLCM_LEVELS    = 16

# -----------------------------
# Helpers: Crop
# -----------------------------
def _roi_bbox(gray_crop, dark_q=0.30):
    thr = np.quantile(gray_crop, dark_q)
    mask = (gray_crop <= thr).astype(np.uint8)
    ys, xs = np.where(mask > 0)
    if len(xs) == 0:
        return None
    x1, x2 = xs.min(), xs.max()
    y1, y2 = ys.min(), ys.max()
    return (x1, y1, x2, y2)

def _danger_near_border_bbox(gray_crop, gap_px=18, dark_q=0.30):
    h, w = gray_crop.shape
    if h < 32 or w < 32:
        return True
    bb = _roi_bbox(gray_crop, dark_q=dark_q)
    if bb is None:
        return False
    x1, y1, x2, y2 = bb
    return (x1 < gap_px or y1 < gap_px or (w - 1 - x2) < gap_px or (h - 1 - y2) < gap_px)

def crop_border_safe(gray, base_trim=0.045, min_trim=0.015, step=0.005, gap_px=22, dark_q=0.30):
    if gray is None:
        return None
    h, w = gray.shape[:2]
    trim = base_trim
    while True:
        dy = int(round(h * trim))
        dx = int(round(w * trim))
        y1, y2 = dy, h - dy
        x1, x2 = dx, w - dx

        if (y2 - y1) < 32 or (x2 - x1) < 32:
            return gray.copy()

        crop = gray[y1:y2, x1:x2].copy()

        if _danger_near_border_bbox(crop, gap_px=gap_px, dark_q=dark_q) and trim > min_trim:
            trim = max(min_trim, trim - step)
            if trim <= 1e-9:
                return gray.copy()
            continue

        return crop

# -----------------------------
# Helpers: Contrast Stretch
# -----------------------------
def contrast_stretch_percentile(gray, p_low=2, p_high=98):
    if gray is None:
        return None
    gray = gray.astype(np.uint8)
    lo, hi = np.percentile(gray, (p_low, p_high))
    if hi <= lo + 1e-6:
        return gray.copy()
    stretched = (gray.astype(np.float32) - lo) * (255.0 / (hi - lo))
    return np.clip(stretched, 0, 255).astype(np.uint8)

def adaptive_percentiles(gray_crop,
                         soft=STRETCH_SOFT, mid=STRETCH_MID, aggressive=STRETCH_AGGRESSIVE,
                         thr_flat=STRETCH_THR_FLAT, thr_mid=STRETCH_THR_MID):
    p2, p98 = np.percentile(gray_crop, (2, 98))
    dyn_ratio = (p98 - p2) / 255.0
    if dyn_ratio < thr_flat:
        return aggressive
    elif dyn_ratio < thr_mid:
        return mid
    else:
        return soft

def adaptive_contrast_stretch(gray_crop):
    p_low, p_high = adaptive_percentiles(gray_crop)
    lo, hi = np.percentile(gray_crop, (p_low, p_high))
    if (hi - lo) < 12:
        return gray_crop.copy(), (int(p_low), int(p_high))
    return contrast_stretch_percentile(gray_crop, p_low=p_low, p_high=p_high), (int(p_low), int(p_high))

# -----------------------------
# Helpers: Median
# -----------------------------
def median_blur(gray, k=5):
    if gray is None:
        return None
    k = int(k)
    if k < 3: k = 3
    if k % 2 == 0: k += 1
    return cv2.medianBlur(gray.astype(np.uint8), k)

# -----------------------------
# Helpers: Threshold (Minimum + fallback)
# -----------------------------
def threshold_minimum_T(gray_u8):
    x = gray_u8.astype(np.float32)
    try:
        t = float(filters.threshold_minimum(x))
        return t, "minimum"
    except Exception:
        if THRESH_FALLBACK == "otsu":
            t, _ = cv2.threshold(gray_u8, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            return float(t), "otsu_fallback"
        else:
            t = float(filters.threshold_triangle(x))
            return t, "triangle_fallback"

def make_binary_mask(gray_u8, T):
    img = gray_u8.astype(np.uint8)
    T = float(T)
    return ((img <= T).astype(np.uint8) * 255).astype(np.uint8)

# -----------------------------
# Helpers: Morphology
# -----------------------------
def make_kernel(shape="ellipse", ksize=3):
    ksize = int(ksize)
    if ksize % 2 == 0:
        ksize += 1
    if shape == "rect":
        return cv2.getStructuringElement(cv2.MORPH_RECT, (ksize, ksize))
    if shape == "cross":
        return cv2.getStructuringElement(cv2.MORPH_CROSS, (ksize, ksize))
    return cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (ksize, ksize))

def ensure_bin_u8(mask_u8):
    return (mask_u8 > 0).astype(np.uint8) * 255

def fill_holes_by_cc(mask_u8, max_hole_ratio=0.30):
    m = ensure_bin_u8(mask_u8).astype(np.uint8)

    fg_area = int((m == 255).sum())
    if fg_area == 0:
        return m

    bg = (m == 0).astype(np.uint8)
    num, lab = cv2.connectedComponents(bg, connectivity=8)
    if num <= 1:
        return m

    border_labels = set()
    border_labels.update(np.unique(lab[0, :]).tolist())
    border_labels.update(np.unique(lab[-1, :]).tolist())
    border_labels.update(np.unique(lab[:, 0]).tolist())
    border_labels.update(np.unique(lab[:, -1]).tolist())

    hole_mask = np.zeros_like(m, dtype=np.uint8)
    for k in range(1, num):
        if k not in border_labels:
            hole_mask[lab == k] = 255

    hole_area = int((hole_mask == 255).sum())
    if hole_area > int(max_hole_ratio * fg_area):
        return m

    m[hole_mask == 255] = 255
    return m

# -----------------------------
# Helpers: CCL center-prior
# -----------------------------
def pick_component_center_prior(stats, centroids, img_center, min_area_px=300, lam=0.003, keep_largest_only=False):
    K = stats.shape[0] - 1
    if K <= 0:
        return None

    candidates = []
    for lbl in range(1, K + 1):
        area = float(stats[lbl, cv2.CC_STAT_AREA])
        if area < float(min_area_px):
            continue
        cx, cy = centroids[lbl]
        dx = float(cx - img_center[0])
        dy = float(cy - img_center[1])
        dist = (dx*dx + dy*dy) ** 0.5

        if keep_largest_only:
            score = area
        else:
            score = area - lam * dist * area  # merkeze uzaklık cezası

        candidates.append((score, lbl, area, dist))

    if not candidates:
        return None
    candidates.sort(key=lambda x: x[0], reverse=True)
    return candidates[0]

def select_single_roi(mask_u8):
    m = ensure_bin_u8(mask_u8).astype(np.uint8)
    h, w = m.shape[:2]
    center = (w/2.0, h/2.0)

    num, lab, stats, centroids = cv2.connectedComponentsWithStats(m, connectivity=8)
    best = pick_component_center_prior(stats, centroids, center,
                                       min_area_px=MIN_AREA_PX,
                                       lam=LAMBDA_CENTER,
                                       keep_largest_only=KEEP_LARGEST_ONLY)
    if best is None:
        return np.zeros_like(m), 0, None
    score, lbl, area, dist = best
    sel = (lab == int(lbl)).astype(np.uint8) * 255
    return sel.astype(np.uint8), 1, {"label_id": int(lbl), "area": float(area), "dist": float(dist)}

# -----------------------------
# Features: First-order (ROI on STRETCHED image)
# -----------------------------
def _entropy_from_counts(counts):
    total = counts.sum()
    if total <= 0:
        return 0.0
    p = counts[counts > 0] / total
    return float(-(p * np.log2(p)).sum())

def first_order_features(gray_u8, roi_mask_u8, bins=256):
    img = gray_u8.astype(np.uint8)
    m = (roi_mask_u8 > 0)
    roi_vals = img[m]
    if roi_vals.size == 0:
        return {k: np.nan for k in [
            "mean","std","variance","min","max","median","skewness","kurtosis","entropy","energy"
        ]} | {"roi_pixels": 0}

    v = roi_vals.astype(np.float32)
    mu  = float(np.mean(v))
    sd  = float(np.std(v, ddof=0))
    var = float(np.var(v, ddof=0))

    vmin = int(np.min(roi_vals))
    vmax = int(np.max(roi_vals))
    vmed = float(np.median(v))

    sk  = float(skew(v, bias=True))
    ku  = float(kurtosis(v, fisher=True, bias=True))

    counts, _ = np.histogram(roi_vals, bins=bins, range=(0, 256))
    ent = _entropy_from_counts(counts)

    p = counts.astype(np.float64)
    p = p / (p.sum() + 1e-12)
    energy = float((p**2).sum())

    return {
        "mean": mu, "std": sd, "variance": var,
        "min": vmin, "max": vmax, "median": vmed,
        "skewness": sk, "kurtosis": ku,
        "entropy": ent, "energy": energy,
        "roi_pixels": int(roi_vals.size)
    }

# -----------------------------
# Features: Shape (ROI binary mask)
# -----------------------------
def shape_features(roi_mask_u8):
    m = (roi_mask_u8 > 0).astype(np.uint8)
    if m.sum() == 0:
        return {k: np.nan for k in [
            "area","perimeter","circularity","eccentricity","solidity","extent",
            "major_axis_length","minor_axis_length","aspect_ratio",
            "convex_area","bbox_w","bbox_h","equivalent_diameter"
        ]}

    lbl = sk_label(m, connectivity=2)
    props = regionprops(lbl)
    if len(props) == 0:
        return {k: np.nan for k in [
            "area","perimeter","circularity","eccentricity","solidity","extent",
            "major_axis_length","minor_axis_length","aspect_ratio",
            "convex_area","bbox_w","bbox_h","equivalent_diameter"
        ]}

    # tek ROI bekleniyor; en büyük alanı al (safety)
    rp = max(props, key=lambda x: x.area)

    area = float(rp.area)
    per  = float(sk_perimeter(rp.image, neighborhood=8))  # rp.image -> bbox içindeki ROI

    # circularity
    if per <= 1e-9:
        circ = np.nan
    else:
        circ = float(4.0 * math.pi * area / (per * per))

    ecc  = float(getattr(rp, "eccentricity", np.nan))
    sol  = float(getattr(rp, "solidity", np.nan))
    ext  = float(getattr(rp, "extent", np.nan))

    maj  = float(getattr(rp, "major_axis_length", np.nan))
    minr = float(getattr(rp, "minor_axis_length", np.nan))
    ar   = float(maj / (minr + 1e-12)) if (np.isfinite(maj) and np.isfinite(minr)) else np.nan

    cxa  = float(getattr(rp, "convex_area", np.nan))
    eqd  = float(getattr(rp, "equivalent_diameter", np.nan))

    minr0, minc0, maxr0, maxc0 = rp.bbox
    bbox_w = float(maxc0 - minc0)
    bbox_h = float(maxr0 - minr0)

    return {
        "area": area,
        "perimeter": per,
        "circularity": circ,
        "eccentricity": ecc,
        "solidity": sol,
        "extent": ext,
        "major_axis_length": maj,
        "minor_axis_length": minr,
        "aspect_ratio": ar,
        "convex_area": cxa,
        "bbox_w": bbox_w,
        "bbox_h": bbox_h,
        "equivalent_diameter": eqd
    }

# -----------------------------
# Features: GLCM (ROI texture on STRETCHED image within ROI bbox)
# -----------------------------
def glcm_features(gray_u8, roi_mask_u8, distances, angles, levels=16):
    img = gray_u8.astype(np.uint8)
    m = (roi_mask_u8 > 0).astype(np.uint8)
    if m.sum() == 0:
        return {f"glcm_{k}": np.nan for k in ["contrast","dissimilarity","homogeneity","energy","correlation","ASM"]}

    ys, xs = np.where(m > 0)
    y1, y2 = ys.min(), ys.max()
    x1, x2 = xs.min(), xs.max()

    patch = img[y1:y2+1, x1:x2+1].copy()
    pmask = m[y1:y2+1, x1:x2+1].copy()

    if patch.size == 0:
        return {f"glcm_{k}": np.nan for k in ["contrast","dissimilarity","homogeneity","energy","correlation","ASM"]}

    # quantization: 0..255 -> 0..levels-1
    q = (patch.astype(np.float32) * (levels / 256.0)).astype(np.int32)
    q = np.clip(q, 0, levels-1).astype(np.uint8)

    # ROI dışını 0'a çek (background etkisini sınırlamak için maskeyi uygula)
    q[pmask == 0] = 0

    glcm = graycomatrix(
        q,
        distances=distances,
        angles=angles,
        levels=levels,
        symmetric=True,
        normed=True
    )

    out = {}
    for prop in ["contrast","dissimilarity","homogeneity","energy","correlation","ASM"]:
        vals = graycoprops(glcm, prop)  # shape: (len(distances), len(angles))
        out[f"glcm_{prop}"] = float(np.mean(vals))
    return out

# -----------------------------
# Main: run pipeline for one image
# -----------------------------
kernel_e = make_kernel(ERODE_KERNEL_SHAPE, ERODE_KSIZE)
kernel_d = make_kernel(DILATE_KERNEL_SHAPE, DILATE_KSIZE)

def process_one(path):
    bgr = cv2.imread(path)
    if bgr is None:
        return None, "imread_failed"
    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)

    # crop
    crop = crop_border_safe(
        gray,
        base_trim=CROP_BASE_TRIM,
        min_trim=CROP_MIN_TRIM,
        step=CROP_STEP,
        gap_px=CROP_GAP_PX,
        dark_q=CROP_DARK_Q
    )

    # stretch
    stretch, (p_low, p_high) = adaptive_contrast_stretch(crop)

    # median (thresholding input)
    med = median_blur(stretch, k=MEDIAN_K)

    # threshold (minimum)
    T, th_tag = threshold_minimum_T(med)
    binary = make_binary_mask(med, T)

    # morphology: erosion -> dilation -> hole fill
    er = cv2.erode(binary, kernel_e, iterations=int(ERODE_ITER))
    dl = cv2.dilate(er, kernel_d, iterations=int(DILATE_ITER))
    filled = fill_holes_by_cc(dl, max_hole_ratio=HOLE_MAX_RATIO)

    # CCL select single ROI (center-prior)
    sel, roi_count, roi_info = select_single_roi(filled)

    meta = {
        "p_low": p_low, "p_high": p_high,
        "threshold_T": float(T),
        "threshold_method": th_tag,
        "roi_count_after_strategy": int(roi_count),
        "roi_area_sel": (np.nan if roi_info is None else roi_info["area"]),
        "roi_dist_center": (np.nan if roi_info is None else roi_info["dist"]),
    }
    return (stretch, sel, meta), None

# -----------------------------
# Run on ALL dataset rows
# -----------------------------
rows = []
fail = 0

for i, r in train_df.reset_index(drop=True).iterrows():
    path = r["file_path"]
    lab  = r["label"]
    image_id = os.path.basename(path)

    out, err = process_one(path)
    if err is not None:
        fail += 1
        rows.append({
            "image_id": image_id,
            "label": lab,
            "file_path": path,
            "status": err
        })
        continue

    stretch_img, roi_mask, meta = out

    # Features
    f1 = first_order_features(stretch_img, roi_mask)
    f2 = shape_features(roi_mask)
    f3 = glcm_features(stretch_img, roi_mask, distances=GLCM_DISTANCES, angles=GLCM_ANGLES, levels=GLCM_LEVELS)

    rows.append({
        "image_id": image_id,
        "label": lab,
        "file_path": path,
        "status": "ok",
        **meta,
        **f1,
        **f2,
        **f3
    })

# -----------------------------
# Save CSV
# -----------------------------
feat_df = pd.DataFrame(rows)

OUT_CSV = "/content/feature_table_full.csv"
feat_df.to_csv(OUT_CSV, index=False)
print(f"\n✅ Feature tablosu CSV kaydedildi: {OUT_CSV}")

# -----------------------------
# Summary prints (hocanın özet istediğine uyacak şekilde)
# -----------------------------
total_imgs = len(feat_df)
ok_imgs    = int((feat_df["status"] == "ok").sum())
fail_imgs  = int((feat_df["status"] != "ok").sum())

roi_ok = feat_df.loc[feat_df["status"]=="ok", "roi_count_after_strategy"].fillna(0).astype(int)
total_roi = int(roi_ok.sum())

print("\n--- Özet ---")
print(f"Toplam görüntü sayısı (df): {len(train_df)}")
print(f"İşlenen toplam satır: {total_imgs}")
print(f"Başarılı: {ok_imgs} | Hatalı: {fail_imgs}")

print(f"Toplam ROI sayısı (ok satırlar): {total_roi}")
print(f"1 görüntü = 1 ROI hedefi (ok satırlar içinde): {(roi_ok==1).sum()} / {len(roi_ok)}")

# distribution (ok only)
dist = roi_ok.value_counts().sort_index()
print("\n--- ROI Sayısı Dağılımı (ok satırlar) ---")
for k, v in dist.items():
    if k == 0:
        print(f"0 ROI: {v}")
    elif k == 1:
        print(f"1 ROI: {v}")
    else:
        print(f"{k} ROI: {v}")

print(f"\nGörüntü başına feature sayısı (kolon): {feat_df.shape[1]}")

print("\n--- GLCM Parametreleri (raporda belirtilecek) ---")
print(f"distances = {GLCM_DISTANCES}")
print("angles    = ['0', 'π/4', 'π/2', '3π/4']")
print(f"levels (quantization) = {GLCM_LEVELS}")

# optional: show head
display(feat_df.head(10))

"""## Tam Veri Seti Üzerinde Pipeline Çalıştırma Sonuçları (n = 2357)"""

# ============================================================
# FULL DATASET PIPELINE -> FEATURES CSV
# Uses: train_df[file_path, label]
# Output: feature_table_full.csv
# ============================================================

import os, math, warnings
import numpy as np
import pandas as pd
import cv2

from skimage import filters
from skimage.measure import label as sk_label, regionprops, perimeter as sk_perimeter
from skimage.feature import graycomatrix, graycoprops
from scipy.stats import skew, kurtosis

warnings.filterwarnings("ignore")

# -----------------------------
# Guard
# -----------------------------
if "train_df" not in globals():
    raise NameError("train_df bulunamadı. Lütfen file_path ve label içeren DataFrame'i (train_df) önce oluştur.")
need_cols = {"file_path", "label"}
if not need_cols.issubset(set(train_df.columns)):
    raise KeyError(f"train_df kolonları eksik. Gerekli: {need_cols}, Mevcut: {list(train_df.columns)}")

print("✅ train_df hazır:", train_df.shape)

# -----------------------------
# PIPELINE PARAMS (istediğinde buradan değiştir)
# -----------------------------
# Crop
CROP_BASE_TRIM = 0.045
CROP_MIN_TRIM  = 0.015
CROP_STEP      = 0.005
CROP_GAP_PX    = 22
CROP_DARK_Q    = 0.30

# Contrast stretch (adaptive)
STRETCH_SOFT       = (6, 99)
STRETCH_MID        = (5, 97)
STRETCH_AGGRESSIVE = (2, 98)
STRETCH_THR_FLAT   = 0.20
STRETCH_THR_MID    = 0.33

# Median blur
MEDIAN_K = 5

# Threshold
THRESH_FALLBACK = "triangle"  # minimum fail olursa: "triangle" veya "otsu"

# Morphology (senin seçtiğin çizgide)
ERODE_KERNEL_SHAPE = "ellipse"
ERODE_KSIZE = 4
ERODE_ITER  = 3

DILATE_KERNEL_SHAPE = "ellipse"
DILATE_KSIZE = 4
DILATE_ITER  = 4

HOLE_MAX_RATIO = 0.30

# CCL strategy (center-prior)
MIN_AREA_PX      = 300
LAMBDA_CENTER    = 0.003
KEEP_LARGEST_ONLY = False

# GLCM params (hocanın istediği)
GLCM_DISTANCES = [1, 2]
GLCM_ANGLES    = [0, np.pi/4, np.pi/2, 3*np.pi/4]
GLCM_LEVELS    = 16

# -----------------------------
# Helpers: Crop
# -----------------------------
def _roi_bbox(gray_crop, dark_q=0.30):
    thr = np.quantile(gray_crop, dark_q)
    mask = (gray_crop <= thr).astype(np.uint8)
    ys, xs = np.where(mask > 0)
    if len(xs) == 0:
        return None
    x1, x2 = xs.min(), xs.max()
    y1, y2 = ys.min(), ys.max()
    return (x1, y1, x2, y2)

def _danger_near_border_bbox(gray_crop, gap_px=18, dark_q=0.30):
    h, w = gray_crop.shape
    if h < 32 or w < 32:
        return True
    bb = _roi_bbox(gray_crop, dark_q=dark_q)
    if bb is None:
        return False
    x1, y1, x2, y2 = bb
    return (x1 < gap_px or y1 < gap_px or (w - 1 - x2) < gap_px or (h - 1 - y2) < gap_px)

def crop_border_safe(gray, base_trim=0.045, min_trim=0.015, step=0.005, gap_px=22, dark_q=0.30):
    if gray is None:
        return None
    h, w = gray.shape[:2]
    trim = base_trim
    while True:
        dy = int(round(h * trim))
        dx = int(round(w * trim))
        y1, y2 = dy, h - dy
        x1, x2 = dx, w - dx

        if (y2 - y1) < 32 or (x2 - x1) < 32:
            return gray.copy()

        crop = gray[y1:y2, x1:x2].copy()

        if _danger_near_border_bbox(crop, gap_px=gap_px, dark_q=dark_q) and trim > min_trim:
            trim = max(min_trim, trim - step)
            if trim <= 1e-9:
                return gray.copy()
            continue

        return crop

# -----------------------------
# Helpers: Contrast Stretch
# -----------------------------
def contrast_stretch_percentile(gray, p_low=2, p_high=98):
    if gray is None:
        return None
    gray = gray.astype(np.uint8)
    lo, hi = np.percentile(gray, (p_low, p_high))
    if hi <= lo + 1e-6:
        return gray.copy()
    stretched = (gray.astype(np.float32) - lo) * (255.0 / (hi - lo))
    return np.clip(stretched, 0, 255).astype(np.uint8)

def adaptive_percentiles(gray_crop,
                         soft=STRETCH_SOFT, mid=STRETCH_MID, aggressive=STRETCH_AGGRESSIVE,
                         thr_flat=STRETCH_THR_FLAT, thr_mid=STRETCH_THR_MID):
    p2, p98 = np.percentile(gray_crop, (2, 98))
    dyn_ratio = (p98 - p2) / 255.0
    if dyn_ratio < thr_flat:
        return aggressive
    elif dyn_ratio < thr_mid:
        return mid
    else:
        return soft

def adaptive_contrast_stretch(gray_crop):
    p_low, p_high = adaptive_percentiles(gray_crop)
    lo, hi = np.percentile(gray_crop, (p_low, p_high))
    if (hi - lo) < 12:
        return gray_crop.copy(), (int(p_low), int(p_high))
    return contrast_stretch_percentile(gray_crop, p_low=p_low, p_high=p_high), (int(p_low), int(p_high))

# -----------------------------
# Helpers: Median
# -----------------------------
def median_blur(gray, k=5):
    if gray is None:
        return None
    k = int(k)
    if k < 3: k = 3
    if k % 2 == 0: k += 1
    return cv2.medianBlur(gray.astype(np.uint8), k)

# -----------------------------
# Helpers: Threshold (Minimum + fallback)
# -----------------------------
def threshold_minimum_T(gray_u8):
    x = gray_u8.astype(np.float32)
    try:
        t = float(filters.threshold_minimum(x))
        return t, "minimum"
    except Exception:
        if THRESH_FALLBACK == "otsu":
            t, _ = cv2.threshold(gray_u8, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            return float(t), "otsu_fallback"
        else:
            t = float(filters.threshold_triangle(x))
            return t, "triangle_fallback"

def make_binary_mask(gray_u8, T):
    img = gray_u8.astype(np.uint8)
    T = float(T)
    return ((img <= T).astype(np.uint8) * 255).astype(np.uint8)

# -----------------------------
# Helpers: Morphology
# -----------------------------
def make_kernel(shape="ellipse", ksize=3):
    ksize = int(ksize)
    if ksize % 2 == 0:
        ksize += 1
    if shape == "rect":
        return cv2.getStructuringElement(cv2.MORPH_RECT, (ksize, ksize))
    if shape == "cross":
        return cv2.getStructuringElement(cv2.MORPH_CROSS, (ksize, ksize))
    return cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (ksize, ksize))

def ensure_bin_u8(mask_u8):
    return (mask_u8 > 0).astype(np.uint8) * 255

def fill_holes_by_cc(mask_u8, max_hole_ratio=0.30):
    m = ensure_bin_u8(mask_u8).astype(np.uint8)

    fg_area = int((m == 255).sum())
    if fg_area == 0:
        return m

    bg = (m == 0).astype(np.uint8)
    num, lab = cv2.connectedComponents(bg, connectivity=8)
    if num <= 1:
        return m

    border_labels = set()
    border_labels.update(np.unique(lab[0, :]).tolist())
    border_labels.update(np.unique(lab[-1, :]).tolist())
    border_labels.update(np.unique(lab[:, 0]).tolist())
    border_labels.update(np.unique(lab[:, -1]).tolist())

    hole_mask = np.zeros_like(m, dtype=np.uint8)
    for k in range(1, num):
        if k not in border_labels:
            hole_mask[lab == k] = 255

    hole_area = int((hole_mask == 255).sum())
    if hole_area > int(max_hole_ratio * fg_area):
        return m

    m[hole_mask == 255] = 255
    return m

# -----------------------------
# Helpers: CCL center-prior
# -----------------------------
def pick_component_center_prior(stats, centroids, img_center, min_area_px=300, lam=0.003, keep_largest_only=False):
    K = stats.shape[0] - 1
    if K <= 0:
        return None

    candidates = []
    for lbl in range(1, K + 1):
        area = float(stats[lbl, cv2.CC_STAT_AREA])
        if area < float(min_area_px):
            continue
        cx, cy = centroids[lbl]
        dx = float(cx - img_center[0])
        dy = float(cy - img_center[1])
        dist = (dx*dx + dy*dy) ** 0.5

        if keep_largest_only:
            score = area
        else:
            score = area - lam * dist * area  # merkeze uzaklık cezası

        candidates.append((score, lbl, area, dist))

    if not candidates:
        return None
    candidates.sort(key=lambda x: x[0], reverse=True)
    return candidates[0]

def select_single_roi(mask_u8):
    m = ensure_bin_u8(mask_u8).astype(np.uint8)
    h, w = m.shape[:2]
    center = (w/2.0, h/2.0)

    num, lab, stats, centroids = cv2.connectedComponentsWithStats(m, connectivity=8)
    best = pick_component_center_prior(stats, centroids, center,
                                       min_area_px=MIN_AREA_PX,
                                       lam=LAMBDA_CENTER,
                                       keep_largest_only=KEEP_LARGEST_ONLY)
    if best is None:
        return np.zeros_like(m), 0, None
    score, lbl, area, dist = best
    sel = (lab == int(lbl)).astype(np.uint8) * 255
    return sel.astype(np.uint8), 1, {"label_id": int(lbl), "area": float(area), "dist": float(dist)}

# -----------------------------
# Features: First-order (ROI on STRETCHED image)
# -----------------------------
def _entropy_from_counts(counts):
    total = counts.sum()
    if total <= 0:
        return 0.0
    p = counts[counts > 0] / total
    return float(-(p * np.log2(p)).sum())

def first_order_features(gray_u8, roi_mask_u8, bins=256):
    img = gray_u8.astype(np.uint8)
    m = (roi_mask_u8 > 0)
    roi_vals = img[m]
    if roi_vals.size == 0:
        return {k: np.nan for k in [
            "mean","std","variance","min","max","median","skewness","kurtosis","entropy","energy"
        ]} | {"roi_pixels": 0}

    v = roi_vals.astype(np.float32)
    mu  = float(np.mean(v))
    sd  = float(np.std(v, ddof=0))
    var = float(np.var(v, ddof=0))

    vmin = int(np.min(roi_vals))
    vmax = int(np.max(roi_vals))
    vmed = float(np.median(v))

    sk  = float(skew(v, bias=True))
    ku  = float(kurtosis(v, fisher=True, bias=True))

    counts, _ = np.histogram(roi_vals, bins=bins, range=(0, 256))
    ent = _entropy_from_counts(counts)

    p = counts.astype(np.float64)
    p = p / (p.sum() + 1e-12)
    energy = float((p**2).sum())

    return {
        "mean": mu, "std": sd, "variance": var,
        "min": vmin, "max": vmax, "median": vmed,
        "skewness": sk, "kurtosis": ku,
        "entropy": ent, "energy": energy,
        "roi_pixels": int(roi_vals.size)
    }

# -----------------------------
# Features: Shape (ROI binary mask)
# -----------------------------
def shape_features(roi_mask_u8):
    m = (roi_mask_u8 > 0).astype(np.uint8)
    if m.sum() == 0:
        return {k: np.nan for k in [
            "area","perimeter","circularity","eccentricity","solidity","extent",
            "major_axis_length","minor_axis_length","aspect_ratio",
            "convex_area","bbox_w","bbox_h","equivalent_diameter"
        ]}

    lbl = sk_label(m, connectivity=2)
    props = regionprops(lbl)
    if len(props) == 0:
        return {k: np.nan for k in [
            "area","perimeter","circularity","eccentricity","solidity","extent",
            "major_axis_length","minor_axis_length","aspect_ratio",
            "convex_area","bbox_w","bbox_h","equivalent_diameter"
        ]}

    # tek ROI bekleniyor; en büyük alanı al (safety)
    rp = max(props, key=lambda x: x.area)

    area = float(rp.area)
    per  = float(sk_perimeter(rp.image, neighborhood=8))  # rp.image -> bbox içindeki ROI

    # circularity
    if per <= 1e-9:
        circ = np.nan
    else:
        circ = float(4.0 * math.pi * area / (per * per))

    ecc  = float(getattr(rp, "eccentricity", np.nan))
    sol  = float(getattr(rp, "solidity", np.nan))
    ext  = float(getattr(rp, "extent", np.nan))

    maj  = float(getattr(rp, "major_axis_length", np.nan))
    minr = float(getattr(rp, "minor_axis_length", np.nan))
    ar   = float(maj / (minr + 1e-12)) if (np.isfinite(maj) and np.isfinite(minr)) else np.nan

    cxa  = float(getattr(rp, "convex_area", np.nan))
    eqd  = float(getattr(rp, "equivalent_diameter", np.nan))

    minr0, minc0, maxr0, maxc0 = rp.bbox
    bbox_w = float(maxc0 - minc0)
    bbox_h = float(maxr0 - minr0)

    return {
        "area": area,
        "perimeter": per,
        "circularity": circ,
        "eccentricity": ecc,
        "solidity": sol,
        "extent": ext,
        "major_axis_length": maj,
        "minor_axis_length": minr,
        "aspect_ratio": ar,
        "convex_area": cxa,
        "bbox_w": bbox_w,
        "bbox_h": bbox_h,
        "equivalent_diameter": eqd
    }

# -----------------------------
# Features: GLCM (ROI texture on STRETCHED image within ROI bbox)
# -----------------------------
def glcm_features(gray_u8, roi_mask_u8, distances, angles, levels=16):
    img = gray_u8.astype(np.uint8)
    m = (roi_mask_u8 > 0).astype(np.uint8)
    if m.sum() == 0:
        return {f"glcm_{k}": np.nan for k in ["contrast","dissimilarity","homogeneity","energy","correlation","ASM"]}

    ys, xs = np.where(m > 0)
    y1, y2 = ys.min(), ys.max()
    x1, x2 = xs.min(), xs.max()

    patch = img[y1:y2+1, x1:x2+1].copy()
    pmask = m[y1:y2+1, x1:x2+1].copy()

    if patch.size == 0:
        return {f"glcm_{k}": np.nan for k in ["contrast","dissimilarity","homogeneity","energy","correlation","ASM"]}

    # quantization: 0..255 -> 0..levels-1
    q = (patch.astype(np.float32) * (levels / 256.0)).astype(np.int32)
    q = np.clip(q, 0, levels-1).astype(np.uint8)

    # ROI dışını 0'a çek (background etkisini sınırlamak için maskeyi uygula)
    q[pmask == 0] = 0

    glcm = graycomatrix(
        q,
        distances=distances,
        angles=angles,
        levels=levels,
        symmetric=True,
        normed=True
    )

    out = {}
    for prop in ["contrast","dissimilarity","homogeneity","energy","correlation","ASM"]:
        vals = graycoprops(glcm, prop)  # shape: (len(distances), len(angles))
        out[f"glcm_{prop}"] = float(np.mean(vals))
    return out

# -----------------------------
# Main: run pipeline for one image
# -----------------------------
kernel_e = make_kernel(ERODE_KERNEL_SHAPE, ERODE_KSIZE)
kernel_d = make_kernel(DILATE_KERNEL_SHAPE, DILATE_KSIZE)

def process_one(path):
    bgr = cv2.imread(path)
    if bgr is None:
        return None, "imread_failed"
    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)

    # crop
    crop = crop_border_safe(
        gray,
        base_trim=CROP_BASE_TRIM,
        min_trim=CROP_MIN_TRIM,
        step=CROP_STEP,
        gap_px=CROP_GAP_PX,
        dark_q=CROP_DARK_Q
    )

    # stretch
    stretch, (p_low, p_high) = adaptive_contrast_stretch(crop)

    # median (thresholding input)
    med = median_blur(stretch, k=MEDIAN_K)

    # threshold (minimum)
    T, th_tag = threshold_minimum_T(med)
    binary = make_binary_mask(med, T)

    # morphology: erosion -> dilation -> hole fill
    er = cv2.erode(binary, kernel_e, iterations=int(ERODE_ITER))
    dl = cv2.dilate(er, kernel_d, iterations=int(DILATE_ITER))
    filled = fill_holes_by_cc(dl, max_hole_ratio=HOLE_MAX_RATIO)

    # CCL select single ROI (center-prior)
    sel, roi_count, roi_info = select_single_roi(filled)

    meta = {
        "p_low": p_low, "p_high": p_high,
        "threshold_T": float(T),
        "threshold_method": th_tag,
        "roi_count_after_strategy": int(roi_count),
        "roi_area_sel": (np.nan if roi_info is None else roi_info["area"]),
        "roi_dist_center": (np.nan if roi_info is None else roi_info["dist"]),
    }
    return (stretch, sel, meta), None

# -----------------------------
# Run on ALL dataset rows
# -----------------------------
rows = []
fail = 0

for i, r in train_df.reset_index(drop=True).iterrows():
    path = r["file_path"]
    lab  = r["label"]
    image_id = os.path.basename(path)

    out, err = process_one(path)
    if err is not None:
        fail += 1
        rows.append({
            "image_id": image_id,
            "label": lab,
            "file_path": path,
            "status": err
        })
        continue

    stretch_img, roi_mask, meta = out

    # Features
    f1 = first_order_features(stretch_img, roi_mask)
    f2 = shape_features(roi_mask)
    f3 = glcm_features(stretch_img, roi_mask, distances=GLCM_DISTANCES, angles=GLCM_ANGLES, levels=GLCM_LEVELS)

    rows.append({
        "image_id": image_id,
        "label": lab,
        "file_path": path,
        "status": "ok",
        **meta,
        **f1,
        **f2,
        **f3
    })

# -----------------------------
# Save CSV
# -----------------------------
feat_df = pd.DataFrame(rows)

OUT_CSV = "/content/feature_table_full.csv"
feat_df.to_csv(OUT_CSV, index=False)
print(f"\n✅ Feature tablosu CSV kaydedildi: {OUT_CSV}")

# -----------------------------
# Summary prints (hocanın özet istediğine uyacak şekilde)
# -----------------------------
total_imgs = len(feat_df)
ok_imgs    = int((feat_df["status"] == "ok").sum())
fail_imgs  = int((feat_df["status"] != "ok").sum())

roi_ok = feat_df.loc[feat_df["status"]=="ok", "roi_count_after_strategy"].fillna(0).astype(int)
total_roi = int(roi_ok.sum())

print("\n--- Özet ---")
print(f"Toplam görüntü sayısı (df): {len(train_df)}")
print(f"İşlenen toplam satır: {total_imgs}")
print(f"Başarılı: {ok_imgs} | Hatalı: {fail_imgs}")

print(f"Toplam ROI sayısı (ok satırlar): {total_roi}")
print(f"1 görüntü = 1 ROI hedefi (ok satırlar içinde): {(roi_ok==1).sum()} / {len(roi_ok)}")

# distribution (ok only)
dist = roi_ok.value_counts().sort_index()
print("\n--- ROI Sayısı Dağılımı (ok satırlar) ---")
for k, v in dist.items():
    if k == 0:
        print(f"0 ROI: {v}")
    elif k == 1:
        print(f"1 ROI: {v}")
    else:
        print(f"{k} ROI: {v}")

print(f"\nGörüntü başına feature sayısı (kolon): {feat_df.shape[1]}")

print("\n--- GLCM Parametreleri (raporda belirtilecek) ---")
print(f"distances = {GLCM_DISTANCES}")
print("angles    = ['0', 'π/4', 'π/2', '3π/4']")
print(f"levels (quantization) = {GLCM_LEVELS}")

# optional: show head
display(feat_df.head(10))

"""Tüm veri seti (`train_df`, 2357 görüntü) üzerinde oluşturulan ön-işleme + segmentasyon + öznitelik çıkarım hattı tek seferde çalıştırılmış ve sonuçlar `feature_table_full.csv` dosyası olarak kaydedilmiştir. Çalıştırma çıktıları aşağıdaki şekilde özetlenmiştir:

- **Toplam görüntü sayısı:** 2357  
- **İşlenen satır sayısı:** 2357  
- **Başarılı işlenen:** 2357 (**Hatalı:** 0)

#### ROI Üretimi / Segmentasyon Başarımı
- **Toplam ROI sayısı (ok satırlar):** 2355  
- **“1 görüntü = 1 ROI” hedefi (ok satırlar içinde):** 2355 / 2357  
- **ROI sayısı dağılımı (ok satırlar):**
  - **0 ROI:** 2 görüntü
  - **1 ROI:** 2355 görüntü

Bu sonuçlar, pipeline’ın büyük çoğunlukla **her görüntüde tek bir ROI üretme** hedefine ulaştığını göstermektedir. **0 ROI çıkan 2 görüntü**, seçilen threshold + morfoloji + CCL stratejisinin bu örneklerde yeterli ROI üretemediği (ROI’nin arka planla ayrışmaması, aşırı düşük kontrast, lezyonun çok küçük kalması veya maske üretiminde kopma gibi) senaryoları işaret etmektedir. Bu iki örnek, ilerleyen aşamalarda ayrı olarak incelenerek gerekirse “fallback” eşikleme/parametre uyarlaması ile iyileştirilebilir.

#### Feature Tablosu Boyutu
- **Görüntü başına feature sayısı (kolon):** 41  

Bu tablo yapısı, her görüntü için **tek bir ROI üzerinden** (0 ROI olanlar hariç) istatistiksel (first-order), şekil (shape) ve doku (GLCM) özelliklerini bir araya getirerek modelleme için doğrudan kullanılabilir bir öznitelik matrisi sağlamaktadır.

#### GLCM Parametreleri (raporda sabit parametre seti)
- **distances:** [1, 2]  
- **angles:** [0, π/4, π/2, 3π/4]  
- **quantization levels:** 16  

"""